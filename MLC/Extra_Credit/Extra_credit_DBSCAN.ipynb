{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total points for this extra credit exercise: 2\n",
    "\n",
    "Make sure that you run all your codes and that all results are printed.\n",
    "\n",
    "Please note: Copying and pasting other people's work is absolutely prohibited. Any such cases will be reported to CUSP's education team and severely punished. Discussion is encouraged, and feel free to exchange ideas with your classmates, but please write your own code and do your own work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as data\n",
    "import sklearn.cluster as cluster\n",
    "import time\n",
    "from sklearn import cluster, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will work with real car crash data from the city of Chicago from the beginning of 2024 up to May 1, 2024. There are 33,725 car crashes that happened in this time, and in the CSV file (Chicago_Car_Crashes_2024), you can find XY coordinates of those events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/fengcharles/Desktop/CUSP/MLC/Extra_Credit/Chicago_Car_Crashes_2024.csv'\n",
    "crash_data = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-87.917163</td>\n",
       "      <td>41.954519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-87.914197</td>\n",
       "      <td>41.953766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-87.914197</td>\n",
       "      <td>41.953766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-87.912395</td>\n",
       "      <td>41.954495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-87.905309</td>\n",
       "      <td>41.976201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33720</th>\n",
       "      <td>-87.525094</td>\n",
       "      <td>41.702573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33721</th>\n",
       "      <td>-87.524691</td>\n",
       "      <td>41.702721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33722</th>\n",
       "      <td>-87.524682</td>\n",
       "      <td>41.701184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33723</th>\n",
       "      <td>-87.524677</td>\n",
       "      <td>41.702028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33724</th>\n",
       "      <td>-87.524587</td>\n",
       "      <td>41.703272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33725 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X          Y\n",
       "0     -87.917163  41.954519\n",
       "1     -87.914197  41.953766\n",
       "2     -87.914197  41.953766\n",
       "3     -87.912395  41.954495\n",
       "4     -87.905309  41.976201\n",
       "...          ...        ...\n",
       "33720 -87.525094  41.702573\n",
       "33721 -87.524691  41.702721\n",
       "33722 -87.524682  41.701184\n",
       "33723 -87.524677  41.702028\n",
       "33724 -87.524587  41.703272\n",
       "\n",
       "[33725 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (50%)\n",
    "\n",
    "Using DBSCAN, try different eps and min_samples to compare the clustering results.\n",
    "\n",
    "a) For min_samples = 100, can you find an eps which produces ~4% of outliers? What is that eps and in which parts of Chicago outliers are located? (25%)\n",
    "\n",
    "b) For eps = .05, can you find min_points which produces ~1% outliers (less and close to 1%, but more than zero)? (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visuDB(data,eps,min_samples):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n",
    "   \n",
    "    print(\"Proportion of unclustered points=\",(1*(db.labels_ < 0)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of unclustered points= 0.04059303187546331\n",
      "Proportion of unclustered points= 0.0028465530022238695\n",
      "Proportion of unclustered points= 0.00014825796886582654\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n"
     ]
    }
   ],
   "source": [
    "min_samples = 100\n",
    "eps_values = np.linspace(0.01, 0.1, 10)\n",
    "\n",
    "# Run visualization across a range of eps values and find the one close to 4% outliers\n",
    "for eps in eps_values:\n",
    "    visuDB(crash_data, eps, min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n",
      "Proportion of unclustered points= 0.0\n"
     ]
    }
   ],
   "source": [
    "min_samples_values = range(1, 101)  \n",
    "eps = 0.05\n",
    "\n",
    "for min_samples in min_samples_values:\n",
    "    visuDB(crash_data, eps, min_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_min_samples_for_outliers(data, eps, target_outlier_percent):\n",
    "    min_samples_values = range(1, 200)  # Wide range to find precise min_samples\n",
    "    results = []\n",
    "\n",
    "    for min_samples in min_samples_values:\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n",
    "        labels = db.labels_\n",
    "        proportion_unclustered = (labels == -1).mean() * 100  # Proportion as a percentage\n",
    "\n",
    "        if 0 < proportion_unclustered <= target_outlier_percent:\n",
    "            results.append((min_samples, proportion_unclustered))\n",
    "            if proportion_unclustered > 0 and proportion_unclustered <= 1.1:  # Close to 1% but more than zero\n",
    "                break  # Stop if the condition is met to save computation time\n",
    "\n",
    "    return results\n",
    "\n",
    "# Setting parameters\n",
    "eps = 0.05\n",
    "target_outlier_percent = 1.1  # Looking for close to 1% but definitely more than zero\n",
    "\n",
    "# Perform the search\n",
    "outlier_results = find_min_samples_for_outliers(crash_data, eps, target_outlier_percent)\n",
    "outlier_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (50%)\n",
    "\n",
    "Using DBSCAN for Anomalous Cluster Detection, detect which areas of Chicago have the highest number of car crashes (i.e., anomalous clusters of car crashes). Scan through a wide range of parameter values. Note: the interpretation is different from above. Now the points assigned to clusters are considered anomalous, and the remaining points are considered normal!\n",
    "\n",
    "a) Find and report the number of detected points (with eps and min_samples) for the situation when 3 noticeable clusters of outliers could be distinguished (25%)\n",
    "\n",
    "b) Report all the maps in your search process (similar to Manhattan exercise in class demo) and answer which one represents those 3 clusters. What are those 3 clusters and where they are located in the city? Why do you think they happen to be outliers? (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
