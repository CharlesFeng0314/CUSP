{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Taxi trips within and outside Manhattan\n",
    "### (Naive Bayes classifier with discrete-valued inputs)\n",
    "\n",
    "Below we apply the Naive Bayes Classifier to predict whether a taxi trip happened within or outside Manhattan. We are given a sample of workday daytime taxi trips with speed and distance information, as well as the number of passengers and the size of the tip.  Speed, distance, and tip information were encoded as discrete categorical variables, with larger values corresponding to faster speeds, longer distances, and higher tips respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tip  dist  speed  pass\n",
      "1323    1     2      1     1\n",
      "1839    2     1      2     1\n",
      "798     4     4      4     1\n",
      "3855    3     1      1     2\n",
      "4552    1     1      1     1\n",
      "\n",
      "1323    0\n",
      "1839    1\n",
      "798     0\n",
      "3855    1\n",
      "4552    0\n",
      "Name: manhattan, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data1 = pd.read_csv(\"NYC_taxi_sample.csv\")\n",
    "data1_X = data1.iloc[:,1:] # tip, distance, speed, and number of passengers\n",
    "data1_y = data1.iloc[:,0] # binary output: 1 if in Manhattan, 0 if outside\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1_X, data1_y, test_size=0.25, random_state=42)\n",
    "print(X_test.head())\n",
    "print()\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple implementation of the Naive Bayes estimator for the training sample statistics $P(x=x^*\\:|\\:y=b)$ and $P(y=b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a binary Naive Bayes Classifier with discrete input attributes.\n",
    "# Assume that the binary output variable takes on values 0 or 1. \n",
    "def trainNaiveBayesDiscrete(X,y):\n",
    "    prior = 1.*y.sum()/y.count()\n",
    "    nbc = {'prior':prior}\n",
    "    X_1 = X[y==1]\n",
    "    X_0 = X[y==0]\n",
    "    for j in X.columns:\n",
    "        nbc[j+'_1'] = X_1[j].value_counts(normalize=True)\n",
    "        nbc[j+'_0'] = X_0[j].value_counts(normalize=True)\n",
    "    return nbc\n",
    "\n",
    "def testNaiveBayesDiscrete(X,nbc):\n",
    "    y_pred = pd.Series(index=X.index,dtype='float64')\n",
    "    for i in X.index:\n",
    "        # compute odds of y=1\n",
    "        y_pred[i] = nbc['prior']/(1-nbc['prior']) # prior odds\n",
    "        for j in X.columns:\n",
    "            thevalue = X.loc[i,j]\n",
    "            if thevalue not in nbc[j+'_1']:\n",
    "                y_pred[i] = y_pred[i]*1E-3\n",
    "            if thevalue not in nbc[j+'_0']:\n",
    "                y_pred[i] = y_pred[i]*1E3\n",
    "            if (thevalue in nbc[j+'_1']) & (thevalue in nbc[j+'_0']):\n",
    "                y_pred[i] = y_pred[i]*(nbc[j+'_1'][thevalue]+1E-3)/(nbc[j+'_0'][thevalue]+1E-3)\n",
    "        # convert odds to probability of y=1\n",
    "        y_pred[i] = y_pred[i]/(1.0+y_pred[i])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior\n",
      "0.4844844844844845\n",
      "\n",
      "tip_1\n",
      "1    0.368285\n",
      "2    0.175103\n",
      "3    0.169938\n",
      "4    0.166322\n",
      "6    0.062500\n",
      "5    0.057851\n",
      "Name: tip, dtype: float64\n",
      "\n",
      "tip_0\n",
      "1    0.558252\n",
      "4    0.166505\n",
      "3    0.097573\n",
      "2    0.092718\n",
      "5    0.050485\n",
      "6    0.034466\n",
      "Name: tip, dtype: float64\n",
      "\n",
      "dist_1\n",
      "1    0.440083\n",
      "2    0.262397\n",
      "3    0.136364\n",
      "4    0.097624\n",
      "6    0.037190\n",
      "5    0.026343\n",
      "Name: dist, dtype: float64\n",
      "\n",
      "dist_0\n",
      "6    0.241748\n",
      "1    0.208252\n",
      "2    0.177184\n",
      "5    0.141748\n",
      "3    0.119417\n",
      "4    0.111650\n",
      "Name: dist, dtype: float64\n",
      "\n",
      "speed_1\n",
      "2    0.411157\n",
      "1    0.310434\n",
      "3    0.158058\n",
      "4    0.072314\n",
      "5    0.033574\n",
      "6    0.014463\n",
      "Name: speed, dtype: float64\n",
      "\n",
      "speed_0\n",
      "2    0.225243\n",
      "3    0.204854\n",
      "4    0.199029\n",
      "5    0.135437\n",
      "6    0.118932\n",
      "1    0.116505\n",
      "Name: speed, dtype: float64\n",
      "\n",
      "pass_1\n",
      "1    0.645661\n",
      "2    0.196281\n",
      "3    0.094525\n",
      "4    0.063533\n",
      "Name: pass, dtype: float64\n",
      "\n",
      "pass_0\n",
      "1    0.704369\n",
      "2    0.130583\n",
      "4    0.109223\n",
      "3    0.055825\n",
      "Name: pass, dtype: float64\n",
      "\n",
      "In sample prediction accuracy: 0.714964964964965\n",
      "Out of sample prediction accuracy: 0.7014253563390848\n",
      "Log-likelihood (train): -2362.8270145996366\n",
      "Log-likelihood (test): -831.8540075663902\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = trainNaiveBayesDiscrete(X_train,y_train)\n",
    "for i,j in naive_bayes_classifier.items():\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print()\n",
    "y_pred_train = testNaiveBayesDiscrete(X_train,naive_bayes_classifier)\n",
    "y_pred_test = testNaiveBayesDiscrete(X_test,naive_bayes_classifier)\n",
    "\n",
    "# measure accuracy for the binary prediction task\n",
    "print('In sample prediction accuracy:',1.0*sum((y_pred_train>0.5)==y_train)/len(y_train))\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_test)/len(y_test))\n",
    "\n",
    "# measure accuracy of the predicted probabilities\n",
    "print('Log-likelihood (train):',sum(np.log(y_pred_train*y_train+(1-y_pred_train)*(1-y_train))))\n",
    "print('Log-likelihood (test):',sum(np.log(y_pred_test*y_test+(1-y_pred_test)*(1-y_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2. Classification of individual vs. commercial properities\n",
    "### (Gaussian Naive Bayes classifier with real-valued inputs)\n",
    "\n",
    "Same dataset as last week's. Based on the sample of characteristics and the prices of the single unit residential and commercial properties sold in zip code 11201 (downtown Brooklyn) between the years 2009 and 2012, build a classifier defining if the sold property was actually residential or commercial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    area      land  year        price\n",
      "64  4296  0.381052  2005   791.433892\n",
      "52  4552  0.587654  1899   900.702988\n",
      "60  7650  1.000000  1931   418.300654\n",
      "5   2820  0.596099  1899  1134.751773\n",
      "72  1820  0.674725  1899  1304.945055\n",
      "\n",
      "64    0\n",
      "52    0\n",
      "60    1\n",
      "5     0\n",
      "72    0\n",
      "Name: bldtype, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"NYC_individual_commercial.csv\")\n",
    "data2_X = data2.iloc[:,:4]\n",
    "data2_y = data2.iloc[:,4]\n",
    "\n",
    "# reduce correlation between attributes when possible\n",
    "# land --> ratio of land area to inside area; price --> price per square foot\n",
    "data2_X['land']=data2_X['land']/data2_X['area']\n",
    "data2_X['price']=data2_X['price']/data2_X['area']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2_X, data2_y, test_size=0.33, random_state=90)\n",
    "print(X_test.head())\n",
    "print()\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple implementation of the Gaussian Naive Bayes estimator for the training sample statistics $\\mu(x\\:|\\:y=b)$, $\\sigma(x\\:|\\:y=b)$, and $P(y=b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a binary Gaussian Naive Bayes Classifier with real-valued input attributes.\n",
    "# Assume that the binary output variable takes on values 0 or 1. \n",
    "def trainGaussianNaiveBayes(X,y):\n",
    "    prior = 1.*y.sum()/y.count()\n",
    "    nbc = {'prior':prior}\n",
    "    X_1 = X[y==1]\n",
    "    X_0 = X[y==0]\n",
    "    for j in X.columns:\n",
    "        nbc[j+'_mu1'] = X_1[j].mean()\n",
    "        nbc[j+'_sigma1'] = X_1[j].std()\n",
    "        nbc[j+'_mu0'] = X_0[j].mean()\n",
    "        nbc[j+'_sigma0'] = X_0[j].std()\n",
    "    return nbc\n",
    "\n",
    "def testGaussianNaiveBayes(X,nbc):\n",
    "    y_pred = pd.Series(index=X.index,dtype='float64')\n",
    "    for i in X.index:\n",
    "        # compute odds of y=1\n",
    "        y_pred[i] = nbc['prior']/(1-nbc['prior']) # prior odds\n",
    "        for j in X.columns:\n",
    "            thevalue = X.loc[i,j]\n",
    "            pdf1 = stats.norm.pdf(thevalue,loc=nbc[j+'_mu1'],scale=nbc[j+'_sigma1'])\n",
    "            pdf0 = stats.norm.pdf(thevalue,loc=nbc[j+'_mu0'],scale=nbc[j+'_sigma0'])\n",
    "            y_pred[i] = y_pred[i]*pdf1/pdf0 if pdf0 > 0 else 1E10\n",
    "        # convert odds to probability of y=1\n",
    "        y_pred[i] = y_pred[i]/(1.0+y_pred[i])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior\n",
      "0.3870967741935484\n",
      "\n",
      "area_mu1\n",
      "16960.5\n",
      "\n",
      "area_sigma1\n",
      "25506.838239117795\n",
      "\n",
      "area_mu0\n",
      "2902.3947368421054\n",
      "\n",
      "area_sigma0\n",
      "1252.3044604221343\n",
      "\n",
      "land_mu1\n",
      "0.842132095043543\n",
      "\n",
      "land_sigma1\n",
      "0.8421904378508392\n",
      "\n",
      "land_mu0\n",
      "0.6088170692188356\n",
      "\n",
      "land_sigma0\n",
      "0.2892678462177817\n",
      "\n",
      "year_mu1\n",
      "1935.5416666666667\n",
      "\n",
      "year_sigma1\n",
      "27.719055079362892\n",
      "\n",
      "year_mu0\n",
      "1916.078947368421\n",
      "\n",
      "year_sigma0\n",
      "51.069312507053596\n",
      "\n",
      "price_mu1\n",
      "379.1549524937095\n",
      "\n",
      "price_sigma1\n",
      "313.2065647182173\n",
      "\n",
      "price_mu0\n",
      "901.8079931869711\n",
      "\n",
      "price_sigma0\n",
      "352.92103007738024\n",
      "\n",
      "In sample prediction accuracy: 0.8870967741935484\n",
      "Out of sample prediction accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = trainGaussianNaiveBayes(X_train,y_train)\n",
    "for i,j in naive_bayes_classifier.items():\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print()\n",
    "y_pred_train = testGaussianNaiveBayes(X_train,naive_bayes_classifier)\n",
    "y_pred_test = testGaussianNaiveBayes(X_test,naive_bayes_classifier)\n",
    "\n",
    "# measure accuracy for the binary prediction task\n",
    "print('In sample prediction accuracy:',1.0*sum((y_pred_train>0.5)==y_train)/len(y_train))\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Package from Sklearn\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample prediction accuracy: 0.8870967741935484\n",
      "Out of sample prediction accuracy: 0.78125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "trained_model = gnb.fit(X_train,y_train)\n",
    "y_pred_train = trained_model.predict_proba(X_train)[:,1]\n",
    "y_pred_test = trained_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# measure accuracy for the binary prediction task\n",
    "print('In sample prediction accuracy:',1.0*sum((y_pred_train>0.5)==y_train)/len(y_train))\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_test)/len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice: Spam classification\n",
    "\n",
    "1. Title:  SPAM E-mail Database\n",
    "\n",
    "2. Sources:\n",
    "   (a) Creators: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt\n",
    "        Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304\n",
    "   (b) Donor: George Forman (gforman at nospam hpl.hp.com)  650-857-7835\n",
    "   (c) Generated: June-July 1999\n",
    "\n",
    "3. Past Usage:\n",
    "   (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.\n",
    "   (b) Determine whether a given email is spam or not.\n",
    "   (c) ~7% misclassification error.\n",
    "       False positives (marking good mail as spam) are very undesirable.\n",
    "       If we insist on zero false positives in the training/testing set,\n",
    "       20-25% of the spam passed through the filter.\n",
    "\n",
    "4. Relevant Information:\n",
    "        The \"spam\" concept is diverse: advertisements for products/web\n",
    "        sites, make money fast schemes, chain letters, pornography...\n",
    "\tThe collection of spam e-mails came from the postmaster and \n",
    "\tindividuals who had filed spam.  The collection of non-spam \n",
    "\te-mails came from filed work and personal e-mails, and hence\n",
    "\tthe word 'george' and the area code '650' are indicators of \n",
    "\tnon-spam.  These are useful when constructing a personalized \n",
    "\tspam filter.  One would either have to blind such non-spam \n",
    "\tindicators or get a very wide collection of non-spam to \n",
    "\tgenerate a general purpose spam filter.\n",
    "\n",
    "        For background on spam:\n",
    "        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! \n",
    "        Communications of the ACM, 41(8):74-83, 1998.\n",
    "\n",
    "5. Number of Instances: 4601 (1813 Spam = 39.4%)\n",
    "\n",
    "6. Number of Attributes: 58 (57 continuous, 1 nominal class label)\n",
    "\n",
    "7. Attribute Information:\n",
    "The last column of 'spambase.data' denotes whether the e-mail was \n",
    "considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \n",
    "Most of the attributes indicate whether a particular word or\n",
    "character was frequently occuring in the e-mail.  The run-length\n",
    "attributes (55-57) measure the length of sequences of consecutive \n",
    "capital letters.  For the statistical measures of each attribute, \n",
    "see the end of this file.  Here are the definitions of the attributes:\n",
    "\n",
    "48 continuous real [0,100] attributes of type word_freq_WORD \n",
    "= percentage of words in the e-mail that match WORD,\n",
    "i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
    "total number of words in e-mail.  A \"word\" in this case is any \n",
    "string of alphanumeric characters bounded by non-alphanumeric \n",
    "characters or end-of-string.\n",
    "\n",
    "6 continuous real [0,100] attributes of type char_freq_CHAR\n",
    "= percentage of characters in the e-mail that match CHAR,\n",
    "i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
    "\n",
    "1 continuous real [1,...] attribute of type capital_run_length_average\n",
    "= average length of uninterrupted sequences of capital letters\n",
    "\n",
    "1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
    "= length of longest uninterrupted sequence of capital letters\n",
    "\n",
    "1 continuous integer [1,...] attribute of type capital_run_length_total\n",
    "= sum of length of uninterrupted sequences of capital letters\n",
    "= total number of capital letters in the e-mail\n",
    "\n",
    "1 nominal {0,1} class attribute of type spam\n",
    "= denotes whether the e-mail was considered spam (1) or not (0), \n",
    "i.e. unsolicited commercial e-mail.  \n",
    "\n",
    "\n",
    "8. Missing Attribute Values: None\n",
    "\n",
    "9. Class Distribution:\n",
    "\tSpam\t  1813  (39.4%)\n",
    "\tNon-Spam  2788  (60.6%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "data = urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\").read().decode('utf8')\n",
    "data_name= urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\").read().decode('utf8')\n",
    "\n",
    "# Read the data\n",
    "data=data.split(\"\\r\\n\")\n",
    "data_spam=[]\n",
    "for i in range(len(data)):\n",
    "    if len(data[i])>0:\n",
    "        temp=data[i].split(\",\")\n",
    "        #change from str to float\n",
    "        t_l=[]\n",
    "        for j in range(len(temp)):\n",
    "            t_l.append(float(temp[j]))\n",
    "        data_spam.append(t_l)\n",
    "\n",
    "#Read the column names\n",
    "temp=data_name.split(\"\\r\\n\")\n",
    "column_names=[]\n",
    "for i in temp:\n",
    "    if (i.startswith('word') or i.startswith('char') or i.startswith('capital')):\n",
    "        column_names.append(i.split(\":\")[0])\n",
    "column_names.append(\"spam\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spam=pd.DataFrame(data_spam)\n",
    "data_spam.columns=column_names\n",
    "data_spam_X=data_spam.iloc[:,0:-1]\n",
    "data_spam_y=data_spam.iloc[:,-1]\n",
    "\n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(data_spam_X, data_spam_y, test_size=0.2, random_state=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Use the Gaussian naive Bayes code that we provided to build your model on the training data, and report the out-of-sample accuracy on your testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior\n",
      "0.389945652173913\n",
      "\n",
      "word_freq_make_1\n",
      "0.00    0.653659\n",
      "0.10    0.021603\n",
      "0.17    0.018815\n",
      "0.09    0.014634\n",
      "0.08    0.009756\n",
      "          ...   \n",
      "0.93    0.000697\n",
      "0.69    0.000697\n",
      "1.26    0.000697\n",
      "0.72    0.000697\n",
      "0.89    0.000697\n",
      "Name: word_freq_make, Length: 103, dtype: float64\n",
      "\n",
      "word_freq_make_0\n",
      "0.00    0.857016\n",
      "0.07    0.005345\n",
      "0.05    0.005345\n",
      "0.06    0.004900\n",
      "0.11    0.004454\n",
      "          ...   \n",
      "3.03    0.000445\n",
      "1.47    0.000445\n",
      "1.63    0.000445\n",
      "1.00    0.000445\n",
      "0.49    0.000445\n",
      "Name: word_freq_make, Length: 110, dtype: float64\n",
      "\n",
      "word_freq_address_1\n",
      "0.00    0.664808\n",
      "0.10    0.011847\n",
      "0.19    0.011150\n",
      "0.17    0.011150\n",
      "0.26    0.010453\n",
      "          ...   \n",
      "1.22    0.000697\n",
      "2.43    0.000697\n",
      "0.70    0.000697\n",
      "0.93    0.000697\n",
      "1.72    0.000697\n",
      "Name: word_freq_address, Length: 116, dtype: float64\n",
      "\n",
      "word_freq_address_0\n",
      "0.00     0.900668\n",
      "14.28    0.011136\n",
      "0.08     0.003563\n",
      "0.16     0.002673\n",
      "0.25     0.002673\n",
      "           ...   \n",
      "0.62     0.000445\n",
      "1.10     0.000445\n",
      "4.10     0.000445\n",
      "1.25     0.000445\n",
      "0.78     0.000445\n",
      "Name: word_freq_address, Length: 108, dtype: float64\n",
      "\n",
      "word_freq_all_1\n",
      "0.00    0.390941\n",
      "0.32    0.018815\n",
      "0.55    0.016725\n",
      "0.40    0.013240\n",
      "0.29    0.013240\n",
      "          ...   \n",
      "1.66    0.000697\n",
      "2.15    0.000697\n",
      "1.61    0.000697\n",
      "1.85    0.000697\n",
      "1.43    0.000697\n",
      "Name: word_freq_all, Length: 165, dtype: float64\n",
      "\n",
      "word_freq_all_0\n",
      "0.00    0.722940\n",
      "0.32    0.006236\n",
      "0.36    0.005791\n",
      "0.22    0.005791\n",
      "0.29    0.005345\n",
      "          ...   \n",
      "2.09    0.000445\n",
      "5.10    0.000445\n",
      "2.17    0.000445\n",
      "4.34    0.000445\n",
      "1.78    0.000445\n",
      "Name: word_freq_all, Length: 175, dtype: float64\n",
      "\n",
      "word_freq_3d_1\n",
      "0.00     0.979094\n",
      "0.17     0.001394\n",
      "35.46    0.001394\n",
      "4.31     0.000697\n",
      "0.60     0.000697\n",
      "0.44     0.000697\n",
      "1.35     0.000697\n",
      "0.10     0.000697\n",
      "0.42     0.000697\n",
      "7.18     0.000697\n",
      "0.52     0.000697\n",
      "0.16     0.000697\n",
      "5.03     0.000697\n",
      "9.16     0.000697\n",
      "0.58     0.000697\n",
      "40.13    0.000697\n",
      "1.16     0.000697\n",
      "0.19     0.000697\n",
      "1.33     0.000697\n",
      "0.95     0.000697\n",
      "0.81     0.000697\n",
      "19.73    0.000697\n",
      "0.49     0.000697\n",
      "0.04     0.000697\n",
      "7.07     0.000697\n",
      "0.06     0.000697\n",
      "42.73    0.000697\n",
      "1.29     0.000697\n",
      "0.57     0.000697\n",
      "Name: word_freq_3d, dtype: float64\n",
      "\n",
      "word_freq_3d_0\n",
      "0.00    0.996437\n",
      "0.13    0.000445\n",
      "0.31    0.000445\n",
      "0.87    0.000445\n",
      "0.55    0.000445\n",
      "0.14    0.000445\n",
      "0.15    0.000445\n",
      "0.21    0.000445\n",
      "0.11    0.000445\n",
      "Name: word_freq_3d, dtype: float64\n",
      "\n",
      "word_freq_our_1\n",
      "0.00    0.377003\n",
      "0.14    0.010453\n",
      "0.80    0.010453\n",
      "0.65    0.010453\n",
      "0.26    0.010453\n",
      "          ...   \n",
      "2.19    0.000697\n",
      "2.46    0.000697\n",
      "2.04    0.000697\n",
      "2.43    0.000697\n",
      "1.00    0.000697\n",
      "Name: word_freq_our, Length: 208, dtype: float64\n",
      "\n",
      "word_freq_our_0\n",
      "0.00    0.782628\n",
      "0.09    0.004454\n",
      "0.32    0.004454\n",
      "0.68    0.004009\n",
      "0.12    0.004009\n",
      "          ...   \n",
      "1.07    0.000445\n",
      "0.89    0.000445\n",
      "1.69    0.000445\n",
      "1.09    0.000445\n",
      "1.02    0.000445\n",
      "Name: word_freq_our, Length: 174, dtype: float64\n",
      "\n",
      "word_freq_over_1\n",
      "0.00    0.629268\n",
      "0.10    0.011150\n",
      "0.32    0.010453\n",
      "0.19    0.010453\n",
      "0.09    0.009756\n",
      "          ...   \n",
      "1.14    0.000697\n",
      "0.95    0.000697\n",
      "0.68    0.000697\n",
      "1.61    0.000697\n",
      "0.76    0.000697\n",
      "Name: word_freq_over, Length: 114, dtype: float64\n",
      "\n",
      "word_freq_over_0\n",
      "0.00    0.887751\n",
      "0.16    0.005345\n",
      "0.10    0.004900\n",
      "0.25    0.004009\n",
      "0.05    0.004009\n",
      "          ...   \n",
      "1.07    0.000445\n",
      "0.48    0.000445\n",
      "0.53    0.000445\n",
      "0.39    0.000445\n",
      "1.03    0.000445\n",
      "Name: word_freq_over, Length: 94, dtype: float64\n",
      "\n",
      "word_freq_remove_1\n",
      "0.00    0.574216\n",
      "0.08    0.016725\n",
      "0.05    0.011150\n",
      "0.19    0.010453\n",
      "0.32    0.010453\n",
      "          ...   \n",
      "0.83    0.000697\n",
      "2.32    0.000697\n",
      "2.00    0.000697\n",
      "1.10    0.000697\n",
      "1.34    0.000697\n",
      "Name: word_freq_remove, Length: 165, dtype: float64\n",
      "\n",
      "word_freq_remove_0\n",
      "0.00    0.985301\n",
      "0.68    0.001336\n",
      "0.59    0.000891\n",
      "0.22    0.000891\n",
      "0.23    0.000891\n",
      "1.78    0.000891\n",
      "0.04    0.000891\n",
      "0.14    0.000891\n",
      "0.20    0.000445\n",
      "2.22    0.000445\n",
      "0.50    0.000445\n",
      "0.67    0.000445\n",
      "0.21    0.000445\n",
      "0.33    0.000445\n",
      "0.24    0.000445\n",
      "0.25    0.000445\n",
      "0.88    0.000445\n",
      "0.41    0.000445\n",
      "0.49    0.000445\n",
      "0.62    0.000445\n",
      "0.16    0.000445\n",
      "1.23    0.000445\n",
      "0.66    0.000445\n",
      "0.05    0.000445\n",
      "0.30    0.000445\n",
      "3.07    0.000445\n",
      "Name: word_freq_remove, dtype: float64\n",
      "\n",
      "word_freq_internet_1\n",
      "0.00    0.650871\n",
      "0.05    0.013937\n",
      "0.32    0.012544\n",
      "0.18    0.009756\n",
      "0.33    0.008362\n",
      "          ...   \n",
      "1.33    0.000697\n",
      "1.05    0.000697\n",
      "4.62    0.000697\n",
      "3.12    0.000697\n",
      "1.30    0.000697\n",
      "Name: word_freq_internet, Length: 143, dtype: float64\n",
      "\n",
      "word_freq_internet_0\n",
      "0.00    0.928285\n",
      "0.09    0.002673\n",
      "0.08    0.002673\n",
      "0.16    0.002673\n",
      "0.29    0.002227\n",
      "          ...   \n",
      "0.33    0.000445\n",
      "0.59    0.000445\n",
      "2.63    0.000445\n",
      "0.01    0.000445\n",
      "0.64    0.000445\n",
      "Name: word_freq_internet, Length: 77, dtype: float64\n",
      "\n",
      "word_freq_order_1\n",
      "0.00    0.705226\n",
      "0.09    0.011847\n",
      "0.10    0.009059\n",
      "0.80    0.008362\n",
      "0.20    0.008362\n",
      "          ...   \n",
      "1.94    0.000697\n",
      "0.70    0.000697\n",
      "0.97    0.000697\n",
      "1.10    0.000697\n",
      "1.35    0.000697\n",
      "Name: word_freq_order, Length: 116, dtype: float64\n",
      "\n",
      "word_freq_order_0\n",
      "0.00    0.924722\n",
      "0.16    0.003118\n",
      "0.23    0.002227\n",
      "0.27    0.002227\n",
      "0.13    0.002227\n",
      "          ...   \n",
      "1.61    0.000445\n",
      "0.91    0.000445\n",
      "1.81    0.000445\n",
      "0.36    0.000445\n",
      "0.06    0.000445\n",
      "Name: word_freq_order, Length: 85, dtype: float64\n",
      "\n",
      "word_freq_mail_1\n",
      "0.00    0.550523\n",
      "0.08    0.011847\n",
      "0.39    0.011150\n",
      "0.10    0.009059\n",
      "0.05    0.008362\n",
      "          ...   \n",
      "1.91    0.000697\n",
      "2.64    0.000697\n",
      "0.87    0.000697\n",
      "1.83    0.000697\n",
      "0.83    0.000697\n",
      "Name: word_freq_mail, Length: 174, dtype: float64\n",
      "\n",
      "word_freq_mail_0\n",
      "0.00    0.826726\n",
      "0.29    0.004009\n",
      "0.27    0.003563\n",
      "0.68    0.003118\n",
      "0.49    0.003118\n",
      "          ...   \n",
      "0.97    0.000445\n",
      "2.55    0.000445\n",
      "1.18    0.000445\n",
      "0.01    0.000445\n",
      "2.68    0.000445\n",
      "Name: word_freq_mail, Length: 177, dtype: float64\n",
      "\n",
      "word_freq_receive_1\n",
      "0.00    0.692683\n",
      "0.10    0.013240\n",
      "0.26    0.011847\n",
      "0.17    0.011150\n",
      "0.30    0.009756\n",
      "          ...   \n",
      "0.04    0.000697\n",
      "0.02    0.000697\n",
      "0.70    0.000697\n",
      "2.61    0.000697\n",
      "0.89    0.000697\n",
      "Name: word_freq_receive, Length: 94, dtype: float64\n",
      "\n",
      "word_freq_receive_0\n",
      "0.00    0.947884\n",
      "2.00    0.004454\n",
      "0.09    0.003118\n",
      "0.08    0.002227\n",
      "0.11    0.001782\n",
      "0.12    0.001782\n",
      "0.34    0.001782\n",
      "0.29    0.001782\n",
      "0.31    0.001782\n",
      "0.14    0.001782\n",
      "0.19    0.001782\n",
      "0.25    0.001782\n",
      "0.15    0.001336\n",
      "0.27    0.001336\n",
      "0.20    0.001336\n",
      "0.48    0.001336\n",
      "0.21    0.000891\n",
      "0.04    0.000891\n",
      "0.33    0.000891\n",
      "0.28    0.000891\n",
      "0.30    0.000891\n",
      "0.54    0.000891\n",
      "0.18    0.000891\n",
      "0.38    0.000891\n",
      "0.13    0.000891\n",
      "0.17    0.000445\n",
      "0.39    0.000445\n",
      "0.07    0.000445\n",
      "0.05    0.000445\n",
      "0.42    0.000445\n",
      "0.26    0.000445\n",
      "0.77    0.000445\n",
      "0.71    0.000445\n",
      "0.02    0.000445\n",
      "0.86    0.000445\n",
      "0.90    0.000445\n",
      "0.45    0.000445\n",
      "0.10    0.000445\n",
      "0.68    0.000445\n",
      "0.57    0.000445\n",
      "0.03    0.000445\n",
      "0.53    0.000445\n",
      "1.10    0.000445\n",
      "0.66    0.000445\n",
      "0.58    0.000445\n",
      "0.06    0.000445\n",
      "0.23    0.000445\n",
      "0.24    0.000445\n",
      "0.87    0.000445\n",
      "0.61    0.000445\n",
      "0.83    0.000445\n",
      "1.31    0.000445\n",
      "1.07    0.000445\n",
      "0.41    0.000445\n",
      "0.50    0.000445\n",
      "0.88    0.000445\n",
      "0.44    0.000445\n",
      "0.36    0.000445\n",
      "Name: word_freq_receive, dtype: float64\n",
      "\n",
      "word_freq_will_1\n",
      "0.00    0.370732\n",
      "0.64    0.013240\n",
      "0.32    0.012544\n",
      "0.57    0.011847\n",
      "0.70    0.011847\n",
      "          ...   \n",
      "0.12    0.000697\n",
      "1.50    0.000697\n",
      "2.04    0.000697\n",
      "1.08    0.000697\n",
      "0.17    0.000697\n",
      "Name: word_freq_will, Length: 206, dtype: float64\n",
      "\n",
      "word_freq_will_0\n",
      "0.00    0.573719\n",
      "2.00    0.006236\n",
      "0.33    0.006236\n",
      "0.34    0.005345\n",
      "0.37    0.004900\n",
      "          ...   \n",
      "1.70    0.000445\n",
      "3.75    0.000445\n",
      "5.12    0.000445\n",
      "2.16    0.000445\n",
      "2.05    0.000445\n",
      "Name: word_freq_will, Length: 278, dtype: float64\n",
      "\n",
      "word_freq_people_1\n",
      "0.00    0.714983\n",
      "0.17    0.018118\n",
      "0.32    0.013937\n",
      "0.30    0.011847\n",
      "0.19    0.011847\n",
      "          ...   \n",
      "1.15    0.000697\n",
      "1.60    0.000697\n",
      "0.50    0.000697\n",
      "0.24    0.000697\n",
      "0.91    0.000697\n",
      "Name: word_freq_people, Length: 113, dtype: float64\n",
      "\n",
      "word_freq_people_0\n",
      "0.00    0.879733\n",
      "0.06    0.004900\n",
      "0.37    0.004454\n",
      "0.27    0.003118\n",
      "0.17    0.002673\n",
      "          ...   \n",
      "5.55    0.000445\n",
      "0.70    0.000445\n",
      "1.80    0.000445\n",
      "1.02    0.000445\n",
      "0.99    0.000445\n",
      "Name: word_freq_people, Length: 110, dtype: float64\n",
      "\n",
      "word_freq_report_1\n",
      "0.00    0.870383\n",
      "0.36    0.011150\n",
      "0.08    0.007666\n",
      "0.05    0.007666\n",
      "0.17    0.006969\n",
      "          ...   \n",
      "3.12    0.000697\n",
      "0.34    0.000697\n",
      "0.21    0.000697\n",
      "0.89    0.000697\n",
      "1.20    0.000697\n",
      "Name: word_freq_report, Length: 77, dtype: float64\n",
      "\n",
      "word_freq_report_0\n",
      "0.00    0.954120\n",
      "0.07    0.002227\n",
      "0.10    0.001782\n",
      "0.19    0.001336\n",
      "0.05    0.001336\n",
      "          ...   \n",
      "0.31    0.000445\n",
      "0.92    0.000445\n",
      "1.58    0.000445\n",
      "0.98    0.000445\n",
      "0.88    0.000445\n",
      "Name: word_freq_report, Length: 73, dtype: float64\n",
      "\n",
      "word_freq_addresses_1\n",
      "0.00    0.843902\n",
      "0.03    0.011150\n",
      "0.18    0.006969\n",
      "1.61    0.005575\n",
      "1.15    0.004878\n",
      "          ...   \n",
      "0.63    0.000697\n",
      "1.94    0.000697\n",
      "0.46    0.000697\n",
      "0.22    0.000697\n",
      "2.06    0.000697\n",
      "Name: word_freq_addresses, Length: 96, dtype: float64\n",
      "\n",
      "word_freq_addresses_0\n",
      "0.00    0.980846\n",
      "0.02    0.002227\n",
      "0.68    0.001336\n",
      "0.08    0.001336\n",
      "0.16    0.001336\n",
      "0.12    0.000891\n",
      "0.01    0.000891\n",
      "0.44    0.000891\n",
      "0.05    0.000891\n",
      "1.16    0.000891\n",
      "1.28    0.000891\n",
      "0.28    0.000445\n",
      "0.14    0.000445\n",
      "1.40    0.000445\n",
      "0.27    0.000445\n",
      "0.29    0.000445\n",
      "2.24    0.000445\n",
      "0.63    0.000445\n",
      "0.25    0.000445\n",
      "0.19    0.000445\n",
      "1.19    0.000445\n",
      "1.49    0.000445\n",
      "0.61    0.000445\n",
      "0.32    0.000445\n",
      "1.36    0.000445\n",
      "1.70    0.000445\n",
      "0.23    0.000445\n",
      "0.06    0.000445\n",
      "Name: word_freq_addresses, dtype: float64\n",
      "\n",
      "word_freq_free_1\n",
      "0.00     0.450174\n",
      "0.32     0.016725\n",
      "0.10     0.012544\n",
      "0.38     0.011150\n",
      "0.25     0.009756\n",
      "           ...   \n",
      "6.45     0.000697\n",
      "16.66    0.000697\n",
      "4.97     0.000697\n",
      "4.27     0.000697\n",
      "1.24     0.000697\n",
      "Name: word_freq_free, Length: 222, dtype: float64\n",
      "\n",
      "word_freq_free_0\n",
      "0.00    0.913140\n",
      "0.13    0.004009\n",
      "0.10    0.002673\n",
      "0.19    0.002673\n",
      "0.11    0.002673\n",
      "          ...   \n",
      "1.01    0.000445\n",
      "1.02    0.000445\n",
      "1.72    0.000445\n",
      "1.23    0.000445\n",
      "0.99    0.000445\n",
      "Name: word_freq_free, Length: 102, dtype: float64\n",
      "\n",
      "word_freq_business_1\n",
      "0.00    0.611150\n",
      "0.32    0.013937\n",
      "0.37    0.011847\n",
      "0.20    0.011150\n",
      "0.08    0.009756\n",
      "          ...   \n",
      "1.84    0.000697\n",
      "0.02    0.000697\n",
      "2.32    0.000697\n",
      "1.09    0.000697\n",
      "2.61    0.000697\n",
      "Name: word_freq_business, Length: 163, dtype: float64\n",
      "\n",
      "word_freq_business_0\n",
      "0.00    0.903786\n",
      "0.10    0.003563\n",
      "0.48    0.003563\n",
      "0.70    0.003118\n",
      "0.13    0.003118\n",
      "          ...   \n",
      "1.70    0.000445\n",
      "0.35    0.000445\n",
      "1.90    0.000445\n",
      "1.64    0.000445\n",
      "0.75    0.000445\n",
      "Name: word_freq_business, Length: 94, dtype: float64\n",
      "\n",
      "word_freq_email_1\n",
      "0.00    0.620906\n",
      "1.11    0.009756\n",
      "0.08    0.007666\n",
      "0.32    0.007666\n",
      "0.44    0.006969\n",
      "          ...   \n",
      "2.41    0.000697\n",
      "1.61    0.000697\n",
      "3.44    0.000697\n",
      "3.18    0.000697\n",
      "2.47    0.000697\n",
      "Name: word_freq_email, Length: 183, dtype: float64\n",
      "\n",
      "word_freq_email_0\n",
      "0.00    0.877506\n",
      "0.05    0.003118\n",
      "0.19    0.003118\n",
      "0.06    0.002673\n",
      "0.12    0.002673\n",
      "          ...   \n",
      "0.67    0.000445\n",
      "0.48    0.000445\n",
      "1.59    0.000445\n",
      "0.60    0.000445\n",
      "2.56    0.000445\n",
      "Name: word_freq_email, Length: 125, dtype: float64\n",
      "\n",
      "word_freq_you_1\n",
      "0.00    0.116376\n",
      "1.31    0.014634\n",
      "1.29    0.009756\n",
      "1.20    0.008362\n",
      "2.56    0.006969\n",
      "          ...   \n",
      "1.64    0.000697\n",
      "6.42    0.000697\n",
      "7.05    0.000697\n",
      "5.59    0.000697\n",
      "1.43    0.000697\n",
      "Name: word_freq_you, Length: 439, dtype: float64\n",
      "\n",
      "word_freq_you_0\n",
      "0.00    0.423163\n",
      "2.00    0.006236\n",
      "3.33    0.005791\n",
      "3.84    0.005345\n",
      "1.49    0.004900\n",
      "          ...   \n",
      "3.53    0.000445\n",
      "1.14    0.000445\n",
      "3.96    0.000445\n",
      "2.67    0.000445\n",
      "3.31    0.000445\n",
      "Name: word_freq_you, Length: 431, dtype: float64\n",
      "\n",
      "word_freq_credit_1\n",
      "0.00    0.791638\n",
      "0.17    0.011150\n",
      "0.20    0.009756\n",
      "0.23    0.009059\n",
      "0.16    0.007666\n",
      "          ...   \n",
      "3.12    0.000697\n",
      "0.10    0.000697\n",
      "4.76    0.000697\n",
      "1.04    0.000697\n",
      "3.26    0.000697\n",
      "Name: word_freq_credit, Length: 123, dtype: float64\n",
      "\n",
      "word_freq_credit_0\n",
      "0.00    0.980846\n",
      "0.19    0.001782\n",
      "0.06    0.001782\n",
      "0.24    0.001336\n",
      "0.05    0.001336\n",
      "0.39    0.000891\n",
      "0.48    0.000891\n",
      "0.01    0.000891\n",
      "1.60    0.000445\n",
      "0.16    0.000445\n",
      "0.59    0.000445\n",
      "1.49    0.000445\n",
      "0.03    0.000445\n",
      "1.67    0.000445\n",
      "2.70    0.000445\n",
      "0.69    0.000445\n",
      "0.23    0.000445\n",
      "0.02    0.000445\n",
      "2.22    0.000445\n",
      "0.30    0.000445\n",
      "1.26    0.000445\n",
      "0.22    0.000445\n",
      "0.15    0.000445\n",
      "0.32    0.000445\n",
      "0.34    0.000445\n",
      "0.29    0.000445\n",
      "0.45    0.000445\n",
      "0.09    0.000445\n",
      "0.13    0.000445\n",
      "0.07    0.000445\n",
      "0.67    0.000445\n",
      "Name: word_freq_credit, dtype: float64\n",
      "\n",
      "word_freq_your_1\n",
      "0.00     0.191638\n",
      "1.36     0.010453\n",
      "0.64     0.009756\n",
      "0.92     0.008362\n",
      "1.38     0.007666\n",
      "           ...   \n",
      "6.45     0.000697\n",
      "1.93     0.000697\n",
      "3.73     0.000697\n",
      "11.11    0.000697\n",
      "3.59     0.000697\n",
      "Name: word_freq_your, Length: 339, dtype: float64\n",
      "\n",
      "word_freq_your_0\n",
      "0.00    0.654788\n",
      "0.22    0.004900\n",
      "8.00    0.004454\n",
      "1.16    0.004454\n",
      "0.42    0.004009\n",
      "          ...   \n",
      "1.81    0.000445\n",
      "3.17    0.000445\n",
      "2.59    0.000445\n",
      "1.91    0.000445\n",
      "2.43    0.000445\n",
      "Name: word_freq_your, Length: 255, dtype: float64\n",
      "\n",
      "word_freq_font_1\n",
      "0.00     0.951220\n",
      "0.36     0.001394\n",
      "0.62     0.001394\n",
      "17.10    0.001394\n",
      "0.31     0.001394\n",
      "           ...   \n",
      "0.46     0.000697\n",
      "1.50     0.000697\n",
      "10.86    0.000697\n",
      "8.84     0.000697\n",
      "1.23     0.000697\n",
      "Name: word_freq_font, Length: 63, dtype: float64\n",
      "\n",
      "word_freq_font_0\n",
      "0.00     0.992428\n",
      "8.29     0.000445\n",
      "10.25    0.000445\n",
      "0.29     0.000445\n",
      "0.58     0.000445\n",
      "0.25     0.000445\n",
      "6.29     0.000445\n",
      "0.07     0.000445\n",
      "1.05     0.000445\n",
      "8.81     0.000445\n",
      "7.22     0.000445\n",
      "2.24     0.000445\n",
      "7.12     0.000445\n",
      "6.75     0.000445\n",
      "0.11     0.000445\n",
      "8.85     0.000445\n",
      "8.00     0.000445\n",
      "8.33     0.000445\n",
      "Name: word_freq_font, dtype: float64\n",
      "\n",
      "word_freq_000_1\n",
      "0.00    0.675958\n",
      "0.34    0.012544\n",
      "0.36    0.009756\n",
      "0.60    0.007666\n",
      "0.44    0.006969\n",
      "          ...   \n",
      "3.57    0.000697\n",
      "1.92    0.000697\n",
      "0.03    0.000697\n",
      "0.66    0.000697\n",
      "1.30    0.000697\n",
      "Name: word_freq_000, Length: 151, dtype: float64\n",
      "\n",
      "word_freq_000_0\n",
      "0.00    0.971047\n",
      "0.05    0.002227\n",
      "0.25    0.001782\n",
      "0.09    0.001782\n",
      "0.10    0.001782\n",
      "0.15    0.001336\n",
      "0.04    0.001336\n",
      "0.21    0.001336\n",
      "0.23    0.001336\n",
      "0.48    0.001336\n",
      "0.07    0.001336\n",
      "0.06    0.000891\n",
      "0.22    0.000891\n",
      "0.39    0.000891\n",
      "0.20    0.000891\n",
      "0.08    0.000891\n",
      "0.13    0.000891\n",
      "0.33    0.000891\n",
      "0.96    0.000891\n",
      "0.11    0.000891\n",
      "1.25    0.000445\n",
      "0.12    0.000445\n",
      "0.50    0.000445\n",
      "0.41    0.000445\n",
      "0.34    0.000445\n",
      "0.18    0.000445\n",
      "0.19    0.000445\n",
      "0.97    0.000445\n",
      "0.02    0.000445\n",
      "0.01    0.000445\n",
      "2.12    0.000445\n",
      "0.38    0.000445\n",
      "Name: word_freq_000, dtype: float64\n",
      "\n",
      "word_freq_money_1\n",
      "0.00    0.620906\n",
      "0.32    0.014634\n",
      "0.08    0.013937\n",
      "0.30    0.012544\n",
      "0.20    0.011150\n",
      "          ...   \n",
      "0.15    0.000697\n",
      "0.66    0.000697\n",
      "1.00    0.000697\n",
      "0.87    0.000697\n",
      "0.75    0.000697\n",
      "Name: word_freq_money, Length: 121, dtype: float64\n",
      "\n",
      "word_freq_money_0\n",
      "0.00    0.979955\n",
      "0.06    0.000891\n",
      "0.42    0.000891\n",
      "0.16    0.000891\n",
      "0.56    0.000891\n",
      "0.08    0.000891\n",
      "0.39    0.000891\n",
      "0.05    0.000891\n",
      "0.80    0.000445\n",
      "1.69    0.000445\n",
      "1.83    0.000445\n",
      "1.16    0.000445\n",
      "1.66    0.000445\n",
      "0.77    0.000445\n",
      "0.69    0.000445\n",
      "1.73    0.000445\n",
      "0.03    0.000445\n",
      "9.09    0.000445\n",
      "0.84    0.000445\n",
      "0.28    0.000445\n",
      "0.33    0.000445\n",
      "0.37    0.000445\n",
      "0.58    0.000445\n",
      "0.40    0.000445\n",
      "1.60    0.000445\n",
      "0.74    0.000445\n",
      "0.45    0.000445\n",
      "0.13    0.000445\n",
      "0.46    0.000445\n",
      "1.04    0.000445\n",
      "0.17    0.000445\n",
      "0.24    0.000445\n",
      "0.48    0.000445\n",
      "0.72    0.000445\n",
      "0.23    0.000445\n",
      "0.07    0.000445\n",
      "0.61    0.000445\n",
      "0.38    0.000445\n",
      "0.73    0.000445\n",
      "Name: word_freq_money, dtype: float64\n",
      "\n",
      "word_freq_hp_1\n",
      "0.00    0.972125\n",
      "0.05    0.002787\n",
      "0.34    0.002091\n",
      "0.68    0.001394\n",
      "0.95    0.001394\n",
      "0.38    0.001394\n",
      "0.09    0.001394\n",
      "0.02    0.001394\n",
      "1.18    0.000697\n",
      "1.49    0.000697\n",
      "0.70    0.000697\n",
      "0.49    0.000697\n",
      "0.32    0.000697\n",
      "0.17    0.000697\n",
      "3.58    0.000697\n",
      "0.57    0.000697\n",
      "2.06    0.000697\n",
      "0.98    0.000697\n",
      "0.44    0.000697\n",
      "0.26    0.000697\n",
      "1.46    0.000697\n",
      "0.33    0.000697\n",
      "0.36    0.000697\n",
      "0.19    0.000697\n",
      "0.52    0.000697\n",
      "0.71    0.000697\n",
      "1.19    0.000697\n",
      "0.10    0.000697\n",
      "1.16    0.000697\n",
      "0.11    0.000697\n",
      "0.21    0.000697\n",
      "Name: word_freq_hp, dtype: float64\n",
      "\n",
      "word_freq_hp_0\n",
      "0.00    0.633853\n",
      "0.90    0.004009\n",
      "0.49    0.004009\n",
      "2.63    0.004009\n",
      "1.69    0.003563\n",
      "          ...   \n",
      "2.25    0.000445\n",
      "1.82    0.000445\n",
      "3.04    0.000445\n",
      "3.23    0.000445\n",
      "2.35    0.000445\n",
      "Name: word_freq_hp, Length: 345, dtype: float64\n",
      "\n",
      "word_freq_hpl_1\n",
      "0.00    0.984669\n",
      "0.05    0.002787\n",
      "0.39    0.000697\n",
      "0.98    0.000697\n",
      "0.34    0.000697\n",
      "0.57    0.000697\n",
      "0.70    0.000697\n",
      "1.49    0.000697\n",
      "1.22    0.000697\n",
      "0.44    0.000697\n",
      "1.46    0.000697\n",
      "0.11    0.000697\n",
      "0.36    0.000697\n",
      "0.26    0.000697\n",
      "0.52    0.000697\n",
      "1.36    0.000697\n",
      "1.19    0.000697\n",
      "0.10    0.000697\n",
      "0.09    0.000697\n",
      "0.21    0.000697\n",
      "Name: word_freq_hpl, dtype: float64\n",
      "\n",
      "word_freq_hpl_0\n",
      "0.00    0.726503\n",
      "0.74    0.004454\n",
      "0.68    0.003563\n",
      "1.19    0.003563\n",
      "0.58    0.003118\n",
      "          ...   \n",
      "2.72    0.000445\n",
      "2.00    0.000445\n",
      "0.09    0.000445\n",
      "1.27    0.000445\n",
      "0.39    0.000445\n",
      "Name: word_freq_hpl, Length: 246, dtype: float64\n",
      "\n",
      "word_freq_george_1\n",
      "0.00    0.995819\n",
      "0.18    0.002787\n",
      "0.43    0.000697\n",
      "1.28    0.000697\n",
      "Name: word_freq_george, dtype: float64\n",
      "\n",
      "word_freq_george_0\n",
      "0.00     0.725167\n",
      "20.00    0.029399\n",
      "25.00    0.005791\n",
      "0.05     0.004900\n",
      "0.70     0.004009\n",
      "           ...   \n",
      "2.01     0.000445\n",
      "3.47     0.000445\n",
      "2.24     0.000445\n",
      "1.13     0.000445\n",
      "1.46     0.000445\n",
      "Name: word_freq_george, Length: 211, dtype: float64\n",
      "\n",
      "word_freq_650_1\n",
      "0.00    0.981882\n",
      "0.24    0.001394\n",
      "0.64    0.000697\n",
      "0.48    0.000697\n",
      "0.42    0.000697\n",
      "0.94    0.000697\n",
      "1.66    0.000697\n",
      "0.28    0.000697\n",
      "0.36    0.000697\n",
      "0.44    0.000697\n",
      "0.81    0.000697\n",
      "1.20    0.000697\n",
      "0.54    0.000697\n",
      "1.36    0.000697\n",
      "0.19    0.000697\n",
      "9.09    0.000697\n",
      "0.31    0.000697\n",
      "0.35    0.000697\n",
      "0.68    0.000697\n",
      "0.73    0.000697\n",
      "2.32    0.000697\n",
      "0.16    0.000697\n",
      "8.33    0.000697\n",
      "0.59    0.000697\n",
      "0.10    0.000697\n",
      "0.25    0.000697\n",
      "Name: word_freq_650, dtype: float64\n",
      "\n",
      "word_freq_650_0\n",
      "0.00    0.847661\n",
      "0.63    0.002673\n",
      "2.04    0.002673\n",
      "4.76    0.002673\n",
      "0.58    0.002227\n",
      "          ...   \n",
      "1.06    0.000445\n",
      "0.75    0.000445\n",
      "2.10    0.000445\n",
      "0.21    0.000445\n",
      "0.51    0.000445\n",
      "Name: word_freq_650, Length: 175, dtype: float64\n",
      "\n",
      "word_freq_lab_1\n",
      "0.00    0.993031\n",
      "0.12    0.002091\n",
      "0.05    0.002091\n",
      "0.02    0.000697\n",
      "0.11    0.000697\n",
      "0.06    0.000697\n",
      "0.47    0.000697\n",
      "Name: word_freq_lab, dtype: float64\n",
      "\n",
      "word_freq_lab_0\n",
      "0.00     0.870379\n",
      "0.58     0.003118\n",
      "4.76     0.003118\n",
      "0.68     0.003118\n",
      "0.50     0.002673\n",
      "           ...   \n",
      "3.84     0.000445\n",
      "0.97     0.000445\n",
      "1.47     0.000445\n",
      "14.28    0.000445\n",
      "1.93     0.000445\n",
      "Name: word_freq_lab, Length: 142, dtype: float64\n",
      "\n",
      "word_freq_labs_1\n",
      "0.00    0.990244\n",
      "0.12    0.002091\n",
      "0.24    0.001394\n",
      "0.62    0.000697\n",
      "3.38    0.000697\n",
      "0.66    0.000697\n",
      "0.18    0.000697\n",
      "0.97    0.000697\n",
      "2.24    0.000697\n",
      "0.39    0.000697\n",
      "0.11    0.000697\n",
      "0.86    0.000697\n",
      "Name: word_freq_labs, dtype: float64\n",
      "\n",
      "word_freq_labs_0\n",
      "0.00    0.836526\n",
      "0.25    0.003118\n",
      "0.17    0.002673\n",
      "0.27    0.002673\n",
      "0.52    0.002673\n",
      "          ...   \n",
      "1.80    0.000445\n",
      "0.92    0.000445\n",
      "0.70    0.000445\n",
      "3.22    0.000445\n",
      "1.12    0.000445\n",
      "Name: word_freq_labs, Length: 159, dtype: float64\n",
      "\n",
      "word_freq_telnet_1\n",
      "0.00    0.997909\n",
      "0.55    0.000697\n",
      "0.40    0.000697\n",
      "1.36    0.000697\n",
      "Name: word_freq_telnet, dtype: float64\n",
      "\n",
      "word_freq_telnet_0\n",
      "0.00    0.897105\n",
      "0.58    0.003118\n",
      "0.70    0.002673\n",
      "0.24    0.002673\n",
      "0.34    0.002227\n",
      "          ...   \n",
      "1.49    0.000445\n",
      "1.08    0.000445\n",
      "0.99    0.000445\n",
      "1.56    0.000445\n",
      "1.44    0.000445\n",
      "Name: word_freq_telnet, Length: 111, dtype: float64\n",
      "\n",
      "word_freq_857_1\n",
      "0.00    0.998606\n",
      "0.47    0.001394\n",
      "Name: word_freq_857, dtype: float64\n",
      "\n",
      "word_freq_857_0\n",
      "0.00    0.926503\n",
      "0.58    0.002673\n",
      "4.76    0.002227\n",
      "0.68    0.002227\n",
      "0.55    0.001782\n",
      "          ...   \n",
      "0.99    0.000445\n",
      "1.56    0.000445\n",
      "0.90    0.000445\n",
      "0.48    0.000445\n",
      "1.44    0.000445\n",
      "Name: word_freq_857, Length: 91, dtype: float64\n",
      "\n",
      "word_freq_data_1\n",
      "0.00    0.963066\n",
      "0.08    0.004181\n",
      "0.33    0.002091\n",
      "0.16    0.002091\n",
      "0.44    0.001394\n",
      "0.34    0.001394\n",
      "0.05    0.001394\n",
      "0.52    0.001394\n",
      "0.26    0.001394\n",
      "0.19    0.001394\n",
      "1.25    0.001394\n",
      "0.14    0.000697\n",
      "0.15    0.000697\n",
      "0.48    0.000697\n",
      "0.03    0.000697\n",
      "0.20    0.000697\n",
      "0.32    0.000697\n",
      "2.12    0.000697\n",
      "0.70    0.000697\n",
      "0.02    0.000697\n",
      "1.03    0.000697\n",
      "0.47    0.000697\n",
      "0.59    0.000697\n",
      "0.40    0.000697\n",
      "0.29    0.000697\n",
      "0.41    0.000697\n",
      "0.53    0.000697\n",
      "0.37    0.000697\n",
      "1.88    0.000697\n",
      "0.25    0.000697\n",
      "0.45    0.000697\n",
      "0.21    0.000697\n",
      "0.27    0.000697\n",
      "0.55    0.000697\n",
      "0.74    0.000697\n",
      "1.13    0.000697\n",
      "1.40    0.000697\n",
      "0.23    0.000697\n",
      "Name: word_freq_data, dtype: float64\n",
      "\n",
      "word_freq_data_0\n",
      "0.00    0.875278\n",
      "0.34    0.004009\n",
      "0.14    0.003118\n",
      "0.27    0.002673\n",
      "0.47    0.002227\n",
      "          ...   \n",
      "0.98    0.000445\n",
      "3.57    0.000445\n",
      "0.70    0.000445\n",
      "0.12    0.000445\n",
      "0.78    0.000445\n",
      "Name: word_freq_data, Length: 165, dtype: float64\n",
      "\n",
      "word_freq_415_1\n",
      "0.00    0.994425\n",
      "0.38    0.000697\n",
      "0.19    0.000697\n",
      "0.12    0.000697\n",
      "0.07    0.000697\n",
      "0.14    0.000697\n",
      "0.43    0.000697\n",
      "0.17    0.000697\n",
      "0.30    0.000697\n",
      "Name: word_freq_415, dtype: float64\n",
      "\n",
      "word_freq_415_0\n",
      "0.00    0.925167\n",
      "0.58    0.002673\n",
      "0.68    0.002227\n",
      "4.76    0.002227\n",
      "0.55    0.001782\n",
      "          ...   \n",
      "0.99    0.000445\n",
      "1.56    0.000445\n",
      "0.48    0.000445\n",
      "0.45    0.000445\n",
      "1.44    0.000445\n",
      "Name: word_freq_415, Length: 92, dtype: float64\n",
      "\n",
      "word_freq_85_1\n",
      "0.00    0.973519\n",
      "0.10    0.006272\n",
      "0.19    0.004181\n",
      "0.48    0.001394\n",
      "0.09    0.001394\n",
      "0.03    0.001394\n",
      "0.07    0.000697\n",
      "0.23    0.000697\n",
      "0.58    0.000697\n",
      "0.13    0.000697\n",
      "0.62    0.000697\n",
      "0.12    0.000697\n",
      "0.60    0.000697\n",
      "0.51    0.000697\n",
      "0.68    0.000697\n",
      "1.91    0.000697\n",
      "0.79    0.000697\n",
      "0.33    0.000697\n",
      "0.31    0.000697\n",
      "0.47    0.000697\n",
      "0.43    0.000697\n",
      "0.06    0.000697\n",
      "0.50    0.000697\n",
      "Name: word_freq_85, dtype: float64\n",
      "\n",
      "word_freq_85_0\n",
      "0.00    0.846771\n",
      "0.33    0.003563\n",
      "0.24    0.003563\n",
      "0.58    0.003118\n",
      "0.34    0.002673\n",
      "          ...   \n",
      "3.84    0.000445\n",
      "0.01    0.000445\n",
      "1.50    0.000445\n",
      "4.54    0.000445\n",
      "0.18    0.000445\n",
      "Name: word_freq_85, Length: 156, dtype: float64\n",
      "\n",
      "word_freq_technology_1\n",
      "0.00    0.937282\n",
      "0.43    0.004878\n",
      "0.16    0.003484\n",
      "0.31    0.002787\n",
      "1.03    0.002787\n",
      "0.42    0.002787\n",
      "0.08    0.002787\n",
      "0.09    0.002091\n",
      "0.27    0.002091\n",
      "0.12    0.002091\n",
      "0.19    0.002091\n",
      "0.98    0.001394\n",
      "0.35    0.001394\n",
      "0.25    0.001394\n",
      "0.41    0.001394\n",
      "1.05    0.001394\n",
      "0.85    0.001394\n",
      "0.74    0.001394\n",
      "0.58    0.001394\n",
      "0.86    0.001394\n",
      "0.26    0.001394\n",
      "0.23    0.001394\n",
      "0.24    0.000697\n",
      "1.18    0.000697\n",
      "1.33    0.000697\n",
      "0.54    0.000697\n",
      "1.15    0.000697\n",
      "1.36    0.000697\n",
      "0.71    0.000697\n",
      "1.35    0.000697\n",
      "0.60    0.000697\n",
      "1.62    0.000697\n",
      "0.30    0.000697\n",
      "1.02    0.000697\n",
      "0.02    0.000697\n",
      "0.29    0.000697\n",
      "0.73    0.000697\n",
      "0.13    0.000697\n",
      "0.53    0.000697\n",
      "0.04    0.000697\n",
      "0.05    0.000697\n",
      "0.52    0.000697\n",
      "0.49    0.000697\n",
      "1.42    0.000697\n",
      "0.22    0.000697\n",
      "0.34    0.000697\n",
      "0.45    0.000697\n",
      "0.62    0.000697\n",
      "0.72    0.000697\n",
      "0.64    0.000697\n",
      "Name: word_freq_technology, dtype: float64\n",
      "\n",
      "word_freq_technology_0\n",
      "0.00    0.827617\n",
      "0.09    0.004009\n",
      "0.37    0.003563\n",
      "0.58    0.003563\n",
      "0.11    0.003118\n",
      "          ...   \n",
      "1.13    0.000445\n",
      "2.27    0.000445\n",
      "0.89    0.000445\n",
      "1.39    0.000445\n",
      "1.44    0.000445\n",
      "Name: word_freq_technology, Length: 141, dtype: float64\n",
      "\n",
      "word_freq_1999_1\n",
      "0.00    0.941463\n",
      "0.10    0.002787\n",
      "0.08    0.002787\n",
      "0.31    0.002091\n",
      "0.30    0.002091\n",
      "3.33    0.002091\n",
      "0.26    0.002091\n",
      "1.47    0.002091\n",
      "0.64    0.002091\n",
      "1.34    0.001394\n",
      "0.23    0.001394\n",
      "1.08    0.001394\n",
      "0.32    0.001394\n",
      "0.29    0.001394\n",
      "1.36    0.001394\n",
      "0.42    0.001394\n",
      "0.19    0.001394\n",
      "1.21    0.001394\n",
      "1.96    0.000697\n",
      "0.07    0.000697\n",
      "0.25    0.000697\n",
      "1.63    0.000697\n",
      "1.11    0.000697\n",
      "0.81    0.000697\n",
      "0.40    0.000697\n",
      "0.43    0.000697\n",
      "0.54    0.000697\n",
      "1.24    0.000697\n",
      "0.35    0.000697\n",
      "0.14    0.000697\n",
      "0.15    0.000697\n",
      "0.34    0.000697\n",
      "0.20    0.000697\n",
      "1.49    0.000697\n",
      "1.38    0.000697\n",
      "0.38    0.000697\n",
      "0.12    0.000697\n",
      "1.40    0.000697\n",
      "1.10    0.000697\n",
      "0.06    0.000697\n",
      "0.79    0.000697\n",
      "0.41    0.000697\n",
      "0.93    0.000697\n",
      "0.05    0.000697\n",
      "0.13    0.000697\n",
      "0.22    0.000697\n",
      "0.95    0.000697\n",
      "0.76    0.000697\n",
      "1.46    0.000697\n",
      "1.09    0.000697\n",
      "1.88    0.000697\n",
      "0.55    0.000697\n",
      "0.68    0.000697\n",
      "1.56    0.000697\n",
      "0.37    0.000697\n",
      "1.29    0.000697\n",
      "0.47    0.000697\n",
      "0.17    0.000697\n",
      "Name: word_freq_1999, dtype: float64\n",
      "\n",
      "word_freq_1999_0\n",
      "0.00    0.745212\n",
      "0.24    0.004900\n",
      "0.64    0.004454\n",
      "0.18    0.004009\n",
      "0.22    0.004009\n",
      "          ...   \n",
      "1.55    0.000445\n",
      "1.65    0.000445\n",
      "0.79    0.000445\n",
      "1.69    0.000445\n",
      "0.05    0.000445\n",
      "Name: word_freq_1999, Length: 171, dtype: float64\n",
      "\n",
      "word_freq_parts_1\n",
      "0.00    0.982578\n",
      "0.11    0.003484\n",
      "0.29    0.002091\n",
      "0.12    0.002091\n",
      "0.28    0.000697\n",
      "0.43    0.000697\n",
      "0.25    0.000697\n",
      "1.56    0.000697\n",
      "0.02    0.000697\n",
      "0.41    0.000697\n",
      "0.50    0.000697\n",
      "0.09    0.000697\n",
      "0.03    0.000697\n",
      "0.36    0.000697\n",
      "0.45    0.000697\n",
      "0.42    0.000697\n",
      "0.46    0.000697\n",
      "0.19    0.000697\n",
      "Name: word_freq_parts, dtype: float64\n",
      "\n",
      "word_freq_parts_0\n",
      "0.00    0.982183\n",
      "0.07    0.001782\n",
      "0.02    0.001336\n",
      "0.03    0.000891\n",
      "0.06    0.000891\n",
      "0.14    0.000891\n",
      "0.55    0.000891\n",
      "0.80    0.000445\n",
      "1.44    0.000445\n",
      "3.44    0.000445\n",
      "0.72    0.000445\n",
      "0.95    0.000445\n",
      "2.85    0.000445\n",
      "0.04    0.000445\n",
      "8.33    0.000445\n",
      "0.37    0.000445\n",
      "0.09    0.000445\n",
      "7.40    0.000445\n",
      "1.06    0.000445\n",
      "1.22    0.000445\n",
      "0.93    0.000445\n",
      "0.25    0.000445\n",
      "6.45    0.000445\n",
      "0.01    0.000445\n",
      "1.57    0.000445\n",
      "0.16    0.000445\n",
      "0.19    0.000445\n",
      "0.86    0.000445\n",
      "0.90    0.000445\n",
      "0.40    0.000445\n",
      "0.29    0.000445\n",
      "1.02    0.000445\n",
      "Name: word_freq_parts, dtype: float64\n",
      "\n",
      "word_freq_pm_1\n",
      "0.00    0.965157\n",
      "0.10    0.005575\n",
      "0.09    0.003484\n",
      "0.53    0.002787\n",
      "0.19    0.001394\n",
      "0.64    0.001394\n",
      "0.52    0.001394\n",
      "0.47    0.001394\n",
      "0.48    0.001394\n",
      "0.20    0.001394\n",
      "0.34    0.000697\n",
      "0.25    0.000697\n",
      "0.57    0.000697\n",
      "0.11    0.000697\n",
      "0.21    0.000697\n",
      "0.54    0.000697\n",
      "0.72    0.000697\n",
      "0.27    0.000697\n",
      "1.88    0.000697\n",
      "0.66    0.000697\n",
      "0.23    0.000697\n",
      "0.32    0.000697\n",
      "0.04    0.000697\n",
      "1.25    0.000697\n",
      "0.51    0.000697\n",
      "0.02    0.000697\n",
      "0.73    0.000697\n",
      "0.74    0.000697\n",
      "0.33    0.000697\n",
      "0.08    0.000697\n",
      "1.07    0.000697\n",
      "Name: word_freq_pm, dtype: float64\n",
      "\n",
      "word_freq_pm_0\n",
      "0.00    0.884187\n",
      "0.64    0.002673\n",
      "0.19    0.002227\n",
      "0.68    0.002227\n",
      "0.11    0.002227\n",
      "          ...   \n",
      "0.10    0.000445\n",
      "0.86    0.000445\n",
      "0.20    0.000445\n",
      "1.02    0.000445\n",
      "9.75    0.000445\n",
      "Name: word_freq_pm, Length: 144, dtype: float64\n",
      "\n",
      "word_freq_direct_1\n",
      "0.00    0.889199\n",
      "0.08    0.012544\n",
      "0.16    0.006272\n",
      "0.12    0.005575\n",
      "0.46    0.005575\n",
      "          ...   \n",
      "0.27    0.000697\n",
      "0.58    0.000697\n",
      "0.66    0.000697\n",
      "0.52    0.000697\n",
      "0.33    0.000697\n",
      "Name: word_freq_direct, Length: 61, dtype: float64\n",
      "\n",
      "word_freq_direct_0\n",
      "0.00    0.906904\n",
      "0.58    0.002673\n",
      "0.26    0.002227\n",
      "0.10    0.002227\n",
      "2.11    0.002227\n",
      "          ...   \n",
      "1.56    0.000445\n",
      "0.90    0.000445\n",
      "2.12    0.000445\n",
      "0.85    0.000445\n",
      "1.44    0.000445\n",
      "Name: word_freq_direct, Length: 102, dtype: float64\n",
      "\n",
      "word_freq_cs_1\n",
      "0.0    0.999303\n",
      "0.1    0.000697\n",
      "Name: word_freq_cs, dtype: float64\n",
      "\n",
      "word_freq_cs_0\n",
      "0.00    0.946548\n",
      "7.14    0.001782\n",
      "0.31    0.001782\n",
      "0.25    0.000891\n",
      "0.10    0.000891\n",
      "          ...   \n",
      "1.20    0.000445\n",
      "0.75    0.000445\n",
      "0.76    0.000445\n",
      "2.69    0.000445\n",
      "0.21    0.000445\n",
      "Name: word_freq_cs, Length: 93, dtype: float64\n",
      "\n",
      "word_freq_meeting_1\n",
      "0.00    0.986760\n",
      "0.11    0.002091\n",
      "0.06    0.001394\n",
      "0.03    0.001394\n",
      "0.45    0.001394\n",
      "0.37    0.000697\n",
      "0.34    0.000697\n",
      "0.23    0.000697\n",
      "0.32    0.000697\n",
      "0.35    0.000697\n",
      "0.25    0.000697\n",
      "0.13    0.000697\n",
      "0.18    0.000697\n",
      "0.36    0.000697\n",
      "0.38    0.000697\n",
      "Name: word_freq_meeting, dtype: float64\n",
      "\n",
      "word_freq_meeting_0\n",
      "0.00    0.887751\n",
      "3.84    0.002227\n",
      "0.90    0.002227\n",
      "0.71    0.002227\n",
      "0.07    0.001782\n",
      "          ...   \n",
      "1.27    0.000445\n",
      "0.20    0.000445\n",
      "2.81    0.000445\n",
      "0.70    0.000445\n",
      "0.39    0.000445\n",
      "Name: word_freq_meeting, Length: 159, dtype: float64\n",
      "\n",
      "word_freq_original_1\n",
      "0.00    0.958885\n",
      "0.20    0.007666\n",
      "0.06    0.006272\n",
      "0.17    0.004181\n",
      "0.11    0.003484\n",
      "0.18    0.002091\n",
      "0.38    0.002091\n",
      "0.24    0.002091\n",
      "0.07    0.002091\n",
      "0.05    0.001394\n",
      "0.02    0.001394\n",
      "0.16    0.001394\n",
      "0.76    0.000697\n",
      "0.19    0.000697\n",
      "0.04    0.000697\n",
      "0.49    0.000697\n",
      "0.36    0.000697\n",
      "0.89    0.000697\n",
      "0.30    0.000697\n",
      "0.52    0.000697\n",
      "0.08    0.000697\n",
      "0.64    0.000697\n",
      "Name: word_freq_original, dtype: float64\n",
      "\n",
      "word_freq_original_0\n",
      "0.00    0.896214\n",
      "0.68    0.003118\n",
      "0.58    0.001782\n",
      "0.33    0.001782\n",
      "0.26    0.001782\n",
      "          ...   \n",
      "0.86    0.000445\n",
      "2.22    0.000445\n",
      "0.84    0.000445\n",
      "0.45    0.000445\n",
      "0.81    0.000445\n",
      "Name: word_freq_original, Length: 126, dtype: float64\n",
      "\n",
      "word_freq_project_1\n",
      "0.00    0.972125\n",
      "0.08    0.004181\n",
      "0.05    0.003484\n",
      "0.02    0.003484\n",
      "0.16    0.002091\n",
      "0.03    0.001394\n",
      "0.36    0.001394\n",
      "0.26    0.001394\n",
      "0.28    0.001394\n",
      "0.06    0.000697\n",
      "0.80    0.000697\n",
      "0.97    0.000697\n",
      "0.30    0.000697\n",
      "0.44    0.000697\n",
      "0.55    0.000697\n",
      "1.16    0.000697\n",
      "0.39    0.000697\n",
      "1.05    0.000697\n",
      "0.14    0.000697\n",
      "0.04    0.000697\n",
      "0.60    0.000697\n",
      "0.25    0.000697\n",
      "Name: word_freq_project, dtype: float64\n",
      "\n",
      "word_freq_project_0\n",
      "0.00    0.904677\n",
      "0.33    0.003118\n",
      "0.06    0.003118\n",
      "0.10    0.003118\n",
      "0.28    0.003118\n",
      "          ...   \n",
      "2.02    0.000445\n",
      "3.09    0.000445\n",
      "8.10    0.000445\n",
      "0.59    0.000445\n",
      "0.66    0.000445\n",
      "Name: word_freq_project, Length: 130, dtype: float64\n",
      "\n",
      "word_freq_re_1\n",
      "0.00    0.732404\n",
      "0.08    0.013240\n",
      "0.07    0.009756\n",
      "0.10    0.008362\n",
      "0.05    0.007666\n",
      "          ...   \n",
      "1.53    0.000697\n",
      "1.24    0.000697\n",
      "0.77    0.000697\n",
      "1.31    0.000697\n",
      "1.00    0.000697\n",
      "Name: word_freq_re, Length: 112, dtype: float64\n",
      "\n",
      "word_freq_re_0\n",
      "0.00     0.704677\n",
      "0.33     0.004900\n",
      "0.58     0.004009\n",
      "0.61     0.003563\n",
      "0.68     0.003563\n",
      "           ...   \n",
      "0.01     0.000445\n",
      "1.27     0.000445\n",
      "4.34     0.000445\n",
      "14.28    0.000445\n",
      "2.38     0.000445\n",
      "Name: word_freq_re, Length: 210, dtype: float64\n",
      "\n",
      "word_freq_edu_1\n",
      "0.00    0.961672\n",
      "0.08    0.009059\n",
      "0.10    0.005575\n",
      "0.36    0.002091\n",
      "0.09    0.002091\n",
      "0.48    0.001394\n",
      "0.81    0.000697\n",
      "0.44    0.000697\n",
      "1.52    0.000697\n",
      "0.57    0.000697\n",
      "2.50    0.000697\n",
      "0.04    0.000697\n",
      "0.02    0.000697\n",
      "0.62    0.000697\n",
      "0.94    0.000697\n",
      "1.48    0.000697\n",
      "0.98    0.000697\n",
      "1.80    0.000697\n",
      "1.56    0.000697\n",
      "2.73    0.000697\n",
      "0.27    0.000697\n",
      "0.12    0.000697\n",
      "0.46    0.000697\n",
      "0.16    0.000697\n",
      "0.33    0.000697\n",
      "1.16    0.000697\n",
      "0.47    0.000697\n",
      "0.11    0.000697\n",
      "0.07    0.000697\n",
      "0.37    0.000697\n",
      "0.06    0.000697\n",
      "0.38    0.000697\n",
      "Name: word_freq_edu, dtype: float64\n",
      "\n",
      "word_freq_edu_0\n",
      "0.00    0.835189\n",
      "0.27    0.004009\n",
      "0.33    0.002673\n",
      "0.16    0.002673\n",
      "0.28    0.002227\n",
      "          ...   \n",
      "5.05    0.000445\n",
      "0.03    0.000445\n",
      "4.83    0.000445\n",
      "3.10    0.000445\n",
      "0.21    0.000445\n",
      "Name: word_freq_edu, Length: 205, dtype: float64\n",
      "\n",
      "word_freq_table_1\n",
      "0.00    0.987456\n",
      "0.04    0.003484\n",
      "0.03    0.002091\n",
      "0.02    0.001394\n",
      "0.34    0.001394\n",
      "0.09    0.001394\n",
      "0.06    0.000697\n",
      "0.46    0.000697\n",
      "0.11    0.000697\n",
      "0.37    0.000697\n",
      "Name: word_freq_table, dtype: float64\n",
      "\n",
      "word_freq_table_0\n",
      "0.00    0.985301\n",
      "0.05    0.001336\n",
      "0.16    0.000891\n",
      "0.02    0.000891\n",
      "0.39    0.000891\n",
      "0.14    0.000445\n",
      "0.25    0.000445\n",
      "0.61    0.000445\n",
      "1.60    0.000445\n",
      "0.04    0.000445\n",
      "0.18    0.000445\n",
      "0.19    0.000445\n",
      "2.17    0.000445\n",
      "0.81    0.000445\n",
      "0.65    0.000445\n",
      "0.09    0.000445\n",
      "1.02    0.000445\n",
      "0.03    0.000445\n",
      "0.88    0.000445\n",
      "2.12    0.000445\n",
      "0.06    0.000445\n",
      "1.51    0.000445\n",
      "0.12    0.000445\n",
      "0.27    0.000445\n",
      "0.01    0.000445\n",
      "0.72    0.000445\n",
      "1.91    0.000445\n",
      "0.86    0.000445\n",
      "0.73    0.000445\n",
      "Name: word_freq_table, dtype: float64\n",
      "\n",
      "word_freq_conference_1\n",
      "0.00    0.992334\n",
      "0.20    0.002091\n",
      "0.24    0.001394\n",
      "0.11    0.001394\n",
      "0.77    0.000697\n",
      "0.19    0.000697\n",
      "0.30    0.000697\n",
      "0.26    0.000697\n",
      "Name: word_freq_conference, dtype: float64\n",
      "\n",
      "word_freq_conference_0\n",
      "0.00    0.931403\n",
      "0.13    0.004009\n",
      "0.10    0.002673\n",
      "0.28    0.002227\n",
      "0.15    0.002227\n",
      "          ...   \n",
      "0.78    0.000445\n",
      "0.11    0.000445\n",
      "0.43    0.000445\n",
      "0.17    0.000445\n",
      "0.55    0.000445\n",
      "Name: word_freq_conference, Length: 95, dtype: float64\n",
      "\n",
      "char_freq_;_1\n",
      "0.000    0.850871\n",
      "0.010    0.009756\n",
      "0.015    0.006272\n",
      "0.012    0.005575\n",
      "0.011    0.004878\n",
      "           ...   \n",
      "0.156    0.000697\n",
      "1.117    0.000697\n",
      "0.673    0.000697\n",
      "1.024    0.000697\n",
      "0.709    0.000697\n",
      "Name: char_freq_;, Length: 118, dtype: float64\n",
      "\n",
      "char_freq_;_0\n",
      "0.000    0.818263\n",
      "0.019    0.002673\n",
      "0.027    0.002673\n",
      "0.018    0.002227\n",
      "0.073    0.002227\n",
      "           ...   \n",
      "0.105    0.000445\n",
      "0.289    0.000445\n",
      "0.045    0.000445\n",
      "0.349    0.000445\n",
      "0.143    0.000445\n",
      "Name: char_freq_;, Length: 238, dtype: float64\n",
      "\n",
      "char_freq_(_1\n",
      "0.000    0.348432\n",
      "0.058    0.008362\n",
      "0.037    0.007666\n",
      "0.081    0.007666\n",
      "0.052    0.006969\n",
      "           ...   \n",
      "0.280    0.000697\n",
      "0.200    0.000697\n",
      "0.690    0.000697\n",
      "0.169    0.000697\n",
      "0.391    0.000697\n",
      "Name: char_freq_(, Length: 326, dtype: float64\n",
      "\n",
      "char_freq_(_0\n",
      "0.000    0.451225\n",
      "0.143    0.004900\n",
      "0.149    0.004454\n",
      "0.131    0.004454\n",
      "0.139    0.003563\n",
      "           ...   \n",
      "0.536    0.000445\n",
      "0.433    0.000445\n",
      "0.608    0.000445\n",
      "0.695    0.000445\n",
      "0.145    0.000445\n",
      "Name: char_freq_(, Length: 536, dtype: float64\n",
      "\n",
      "char_freq_[_1\n",
      "0.000    0.923345\n",
      "0.028    0.003484\n",
      "0.031    0.002787\n",
      "0.053    0.002787\n",
      "0.027    0.002787\n",
      "           ...   \n",
      "0.347    0.000697\n",
      "0.109    0.000697\n",
      "0.054    0.000697\n",
      "0.185    0.000697\n",
      "0.104    0.000697\n",
      "Name: char_freq_[, Length: 68, dtype: float64\n",
      "\n",
      "char_freq_[_0\n",
      "0.000    0.861915\n",
      "0.066    0.003118\n",
      "0.194    0.002227\n",
      "0.052    0.002227\n",
      "0.031    0.002227\n",
      "           ...   \n",
      "0.335    0.000445\n",
      "0.202    0.000445\n",
      "0.262    0.000445\n",
      "0.085    0.000445\n",
      "0.180    0.000445\n",
      "Name: char_freq_[, Length: 180, dtype: float64\n",
      "\n",
      "char_freq_!_1\n",
      "0.000    0.167247\n",
      "0.010    0.005575\n",
      "0.034    0.004878\n",
      "0.230    0.004878\n",
      "0.537    0.004181\n",
      "           ...   \n",
      "0.684    0.000697\n",
      "0.181    0.000697\n",
      "0.164    0.000697\n",
      "2.249    0.000697\n",
      "1.004    0.000697\n",
      "Name: char_freq_!, Length: 720, dtype: float64\n",
      "\n",
      "char_freq_!_0\n",
      "0.000    0.733185\n",
      "0.045    0.002673\n",
      "0.044    0.002673\n",
      "0.055    0.002673\n",
      "0.022    0.002227\n",
      "           ...   \n",
      "0.353    0.000445\n",
      "0.666    0.000445\n",
      "0.943    0.000445\n",
      "0.866    0.000445\n",
      "0.027    0.000445\n",
      "Name: char_freq_!, Length: 362, dtype: float64\n",
      "\n",
      "char_freq_$_1\n",
      "0.000    0.391638\n",
      "0.118    0.009059\n",
      "0.157    0.006272\n",
      "0.061    0.006272\n",
      "0.107    0.005575\n",
      "           ...   \n",
      "0.297    0.000697\n",
      "0.216    0.000697\n",
      "0.248    0.000697\n",
      "0.340    0.000697\n",
      "0.524    0.000697\n",
      "Name: char_freq_$, Length: 416, dtype: float64\n",
      "\n",
      "char_freq_$_0\n",
      "0.000    0.893987\n",
      "0.016    0.003563\n",
      "0.031    0.003118\n",
      "0.021    0.002673\n",
      "0.005    0.001782\n",
      "           ...   \n",
      "0.242    0.000445\n",
      "0.058    0.000445\n",
      "0.065    0.000445\n",
      "0.169    0.000445\n",
      "0.006    0.000445\n",
      "Name: char_freq_$, Length: 138, dtype: float64\n",
      "\n",
      "char_freq_#_1\n",
      "0.000    0.714286\n",
      "0.013    0.006969\n",
      "0.054    0.006969\n",
      "0.030    0.006272\n",
      "0.015    0.006272\n",
      "           ...   \n",
      "1.570    0.000697\n",
      "0.111    0.000697\n",
      "1.998    0.000697\n",
      "0.268    0.000697\n",
      "0.412    0.000697\n",
      "Name: char_freq_#, Length: 201, dtype: float64\n",
      "\n",
      "char_freq_#_0\n",
      "0.000    0.920713\n",
      "0.026    0.001782\n",
      "0.052    0.001782\n",
      "0.041    0.001782\n",
      "0.095    0.001336\n",
      "           ...   \n",
      "0.473    0.000445\n",
      "0.113    0.000445\n",
      "0.114    0.000445\n",
      "0.080    0.000445\n",
      "0.037    0.000445\n",
      "Name: char_freq_#, Length: 133, dtype: float64\n",
      "\n",
      "capital_run_length_average_1\n",
      "4.000    0.008362\n",
      "1.494    0.007666\n",
      "1.000    0.007666\n",
      "2.000    0.006272\n",
      "3.000    0.006272\n",
      "           ...   \n",
      "3.418    0.000697\n",
      "2.074    0.000697\n",
      "6.978    0.000697\n",
      "2.782    0.000697\n",
      "3.890    0.000697\n",
      "Name: capital_run_length_average, Length: 1035, dtype: float64\n",
      "\n",
      "capital_run_length_average_0\n",
      "1.000    0.121604\n",
      "2.000    0.022272\n",
      "1.800    0.016927\n",
      "1.500    0.012918\n",
      "1.666    0.012027\n",
      "           ...   \n",
      "3.455    0.000445\n",
      "2.589    0.000445\n",
      "2.741    0.000445\n",
      "1.748    0.000445\n",
      "3.596    0.000445\n",
      "Name: capital_run_length_average, Length: 1089, dtype: float64\n",
      "\n",
      "capital_run_length_longest_1\n",
      "12.0     0.052962\n",
      "11.0     0.039024\n",
      "10.0     0.028571\n",
      "19.0     0.025087\n",
      "13.0     0.020906\n",
      "           ...   \n",
      "445.0    0.000697\n",
      "186.0    0.000697\n",
      "404.0    0.000697\n",
      "145.0    0.000697\n",
      "183.0    0.000697\n",
      "Name: capital_run_length_longest, Length: 235, dtype: float64\n",
      "\n",
      "capital_run_length_longest_0\n",
      "1.0       0.121604\n",
      "5.0       0.076615\n",
      "4.0       0.069933\n",
      "11.0      0.060134\n",
      "3.0       0.057906\n",
      "            ...   \n",
      "69.0      0.000445\n",
      "86.0      0.000445\n",
      "62.0      0.000445\n",
      "119.0     0.000445\n",
      "1488.0    0.000445\n",
      "Name: capital_run_length_longest, Length: 111, dtype: float64\n",
      "\n",
      "capital_run_length_total_1\n",
      "139.0     0.011847\n",
      "78.0      0.009059\n",
      "114.0     0.008362\n",
      "54.0      0.007666\n",
      "72.0      0.006969\n",
      "            ...   \n",
      "2213.0    0.000697\n",
      "1257.0    0.000697\n",
      "460.0     0.000697\n",
      "529.0     0.000697\n",
      "3327.0    0.000697\n",
      "Name: capital_run_length_total, Length: 634, dtype: float64\n",
      "\n",
      "capital_run_length_total_0\n",
      "5.0       0.041425\n",
      "9.0       0.021826\n",
      "6.0       0.019599\n",
      "7.0       0.017817\n",
      "4.0       0.016927\n",
      "            ...   \n",
      "265.0     0.000445\n",
      "386.0     0.000445\n",
      "2349.0    0.000445\n",
      "299.0     0.000445\n",
      "1192.0    0.000445\n",
      "Name: capital_run_length_total, Length: 504, dtype: float64\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m testNaiveBayesDiscrete(X_tests,naive_bayes_classifier)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# measure accuracy for the binary prediction task\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn sample prediction accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28msum\u001b[39m((y_pred_train\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m==\u001b[39my_train)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_train))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOut of sample prediction accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28msum\u001b[39m((y_pred_test\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m==\u001b[39my_test)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_test))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# measure accuracy of the predicted probabilities\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39meq)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:6237\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6234\u001b[0m res_name \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_op_result_name(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m   6236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indexed_same(other):\n\u001b[0;32m-> 6237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled Series objects\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6239\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "naive_bayes_classifier = trainNaiveBayesDiscrete(X_trains,y_trains)\n",
    "for i,j in naive_bayes_classifier.items():\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print()\n",
    "y_pred_train = testNaiveBayesDiscrete(X_trains,naive_bayes_classifier)\n",
    "y_pred_test = testNaiveBayesDiscrete(X_tests,naive_bayes_classifier)\n",
    "\n",
    "# measure accuracy for the binary prediction task\n",
    "print('In sample prediction accuracy:',1.0*sum((y_pred_train>0.5)==y_train)/len(y_train))\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_test)/len(y_test))\n",
    "\n",
    "# measure accuracy of the predicted probabilities\n",
    "print('Log-likelihood (train):',sum(np.log(y_pred_train*y_train+(1-y_pred_train)*(1-y_train))))\n",
    "print('Log-likelihood (test):',sum(np.log(y_pred_test*y_test+(1-y_pred_test)*(1-y_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Use the Sklearn package to double check your solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample prediction accuracy: 0.8176630434782609\n",
      "Out of sample prediction accuracy: 0.8371335504885994\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "trained_model = gnb.fit(X_trains,y_trains)\n",
    "y_pred_train = trained_model.predict_proba(X_trains)[:,1]\n",
    "y_pred_test = trained_model.predict_proba(X_tests)[:,1]\n",
    "\n",
    "# measure accuracy for the binary prediction task\n",
    "print('In sample prediction accuracy:',1.0*sum((y_pred_train>0.5)==y_trains)/len(y_trains))\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_tests)/len(y_tests))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised EM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3. Taxi trip classification with partially missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same dataset as before\n",
    "data1 = pd.read_csv(\"NYC_taxi_sample.csv\")\n",
    "data1_X = data1.iloc[:,1:] # tip, distance, speed, and number of passengers\n",
    "data1_y = data1.iloc[:,0] # binary output: 1 if in Manhattan, 0 if outside\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1_X, data1_y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# now let's delete 99% of the labels from the training dataset and see what happens\n",
    "random.seed(2015)\n",
    "Label_index=random.sample(list(range(len(X_train))),int(len(X_train)*0.01))\n",
    "Unlabel_index=[x for x in list(range(len(X_train))) if x not in Label_index]\n",
    "\n",
    "X_train_Labeled=X_train.iloc[Label_index,:]\n",
    "X_train_Unlabeled=X_train.iloc[Unlabel_index,:]   \n",
    "y_train_Labeled=y_train.iloc[Label_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well our Naive Bayes Classifier does using only the small sample of labeled training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "3957\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_Labeled.index))\n",
    "print(len(X_train_Unlabeled.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior\n",
      "0.3333333333333333\n",
      "\n",
      "tip_1\n",
      "1    0.538462\n",
      "5    0.153846\n",
      "3    0.153846\n",
      "4    0.076923\n",
      "2    0.076923\n",
      "Name: tip, dtype: float64\n",
      "\n",
      "tip_0\n",
      "1    0.500000\n",
      "4    0.230769\n",
      "5    0.115385\n",
      "3    0.115385\n",
      "6    0.038462\n",
      "Name: tip, dtype: float64\n",
      "\n",
      "dist_1\n",
      "1    0.538462\n",
      "3    0.307692\n",
      "2    0.076923\n",
      "4    0.076923\n",
      "Name: dist, dtype: float64\n",
      "\n",
      "dist_0\n",
      "1    0.269231\n",
      "2    0.269231\n",
      "6    0.192308\n",
      "5    0.153846\n",
      "3    0.076923\n",
      "4    0.038462\n",
      "Name: dist, dtype: float64\n",
      "\n",
      "speed_1\n",
      "2    0.384615\n",
      "3    0.230769\n",
      "4    0.153846\n",
      "1    0.153846\n",
      "5    0.076923\n",
      "Name: speed, dtype: float64\n",
      "\n",
      "speed_0\n",
      "2    0.346154\n",
      "1    0.192308\n",
      "4    0.153846\n",
      "6    0.115385\n",
      "5    0.115385\n",
      "3    0.076923\n",
      "Name: speed, dtype: float64\n",
      "\n",
      "pass_1\n",
      "1    0.769231\n",
      "4    0.153846\n",
      "3    0.076923\n",
      "Name: pass, dtype: float64\n",
      "\n",
      "pass_0\n",
      "1    0.730769\n",
      "2    0.153846\n",
      "4    0.076923\n",
      "3    0.038462\n",
      "Name: pass, dtype: float64\n",
      "\n",
      "Out of sample prediction accuracy: 0.5656414103525882\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = trainNaiveBayesDiscrete(X_train_Labeled,y_train_Labeled)\n",
    "for i,j in naive_bayes_classifier.items():\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print()\n",
    "y_pred_test = testNaiveBayesDiscrete(X_test,naive_bayes_classifier)\n",
    "\n",
    "# measure accuracy for the binary prediction task\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well we can do using both labeled and unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeNaiveBayesRandom(X_Unlabeled):\n",
    "    nbc = {'prior':0.5}\n",
    "    for j in X_Unlabeled.columns:\n",
    "        thevalues = X_Unlabeled[j].unique()\n",
    "        nbc[j+'_1'] = {}\n",
    "        nbc[j+'_0'] = {}\n",
    "        for jj in thevalues:\n",
    "            nbc[j+'_1'][jj] = np.random.rand()\n",
    "            nbc[j+'_0'][jj] = np.random.rand()\n",
    "    return nbc\n",
    "    \n",
    "def EM(X_Labeled,y_Labeled,X_Unlabeled,num_iters):\n",
    "\n",
    "    # initialize\n",
    "    \n",
    "    t = 0\n",
    "    \n",
    "    if len(y_Labeled) > 0:\n",
    "        nbc = trainNaiveBayesDiscrete(X_Labeled,y_Labeled)\n",
    "    else:\n",
    "        nbc = initializeNaiveBayesRandom(X_Unlabeled)\n",
    "    \n",
    "    while True:\n",
    "        t = t + 1\n",
    "        print('Iteration',t,'of',num_iters)\n",
    "        \n",
    "        # E step - classify with nbc for unlabeled data only\n",
    "        y_pred_Unlabeled = testNaiveBayesDiscrete(X_Unlabeled,nbc)\n",
    "        \n",
    "        # M step\n",
    "        X_for_M_step = pd.concat([X_Labeled,X_Unlabeled],ignore_index=True) \n",
    "        y_for_M_step = pd.concat([y_Labeled,y_pred_Unlabeled],ignore_index=True)\n",
    "        prior = 1.*y_for_M_step.sum()/y_for_M_step.count()\n",
    "        nbc = {'prior':prior}\n",
    "        for j in X_for_M_step.columns:\n",
    "            nbc[j+'_1'] = {}\n",
    "            nbc[j+'_0'] = {}\n",
    "            for theindex in X_for_M_step.index:\n",
    "                current_X = X_for_M_step.loc[theindex,j]\n",
    "                current_y = y_for_M_step.loc[theindex]\n",
    "                if current_X in nbc[j+'_1']:\n",
    "                    nbc[j+'_1'][current_X] += current_y\n",
    "                else:\n",
    "                    nbc[j+'_1'][current_X] = current_y\n",
    "                if current_X in nbc[j+'_0']:\n",
    "                    nbc[j+'_0'][current_X] += (1.0-current_y)\n",
    "                else:\n",
    "                    nbc[j+'_0'][current_X] = 1.0-current_y\n",
    "            # normalize probabilities\n",
    "            tempsum = 0.0\n",
    "            for k in nbc[j+'_1']:\n",
    "                tempsum += nbc[j+'_1'][k]\n",
    "            for k in nbc[j+'_1']:\n",
    "                nbc[j+'_1'][k] /= tempsum\n",
    "            tempsum = 0.0\n",
    "            for k in nbc[j+'_0']:\n",
    "                tempsum += nbc[j+'_0'][k]\n",
    "            for k in nbc[j+'_0']:\n",
    "                nbc[j+'_0'][k] /= tempsum            \n",
    "                       \n",
    "        if t==num_iters:\n",
    "            break\n",
    "            \n",
    "    return nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 50\n",
      "Iteration 2 of 50\n",
      "Iteration 3 of 50\n",
      "Iteration 4 of 50\n",
      "Iteration 5 of 50\n",
      "Iteration 6 of 50\n",
      "Iteration 7 of 50\n",
      "Iteration 8 of 50\n",
      "Iteration 9 of 50\n",
      "Iteration 10 of 50\n",
      "Iteration 11 of 50\n",
      "Iteration 12 of 50\n",
      "Iteration 13 of 50\n",
      "Iteration 14 of 50\n",
      "Iteration 15 of 50\n",
      "Iteration 16 of 50\n",
      "Iteration 17 of 50\n",
      "Iteration 18 of 50\n",
      "Iteration 19 of 50\n",
      "Iteration 20 of 50\n",
      "Iteration 21 of 50\n",
      "Iteration 22 of 50\n",
      "Iteration 23 of 50\n",
      "Iteration 24 of 50\n",
      "Iteration 25 of 50\n",
      "Iteration 26 of 50\n",
      "Iteration 27 of 50\n",
      "Iteration 28 of 50\n",
      "Iteration 29 of 50\n",
      "Iteration 30 of 50\n",
      "Iteration 31 of 50\n",
      "Iteration 32 of 50\n",
      "Iteration 33 of 50\n",
      "Iteration 34 of 50\n",
      "Iteration 35 of 50\n",
      "Iteration 36 of 50\n",
      "Iteration 37 of 50\n",
      "Iteration 38 of 50\n",
      "Iteration 39 of 50\n",
      "Iteration 40 of 50\n",
      "Iteration 41 of 50\n",
      "Iteration 42 of 50\n",
      "Iteration 43 of 50\n",
      "Iteration 44 of 50\n",
      "Iteration 45 of 50\n",
      "Iteration 46 of 50\n",
      "Iteration 47 of 50\n",
      "Iteration 48 of 50\n",
      "Iteration 49 of 50\n",
      "Iteration 50 of 50\n",
      "prior\n",
      "0.5341637635239567\n",
      "\n",
      "tip_1\n",
      "{5: 0.05386104028421211, 4: 0.16599055483023595, 1: 0.42406581491319334, 3: 0.14941587116447697, 6: 0.05519960357352501, 2: 0.1514671152343567}\n",
      "\n",
      "tip_0\n",
      "{5: 0.05427537853170885, 4: 0.16690474216225212, 1: 0.5145491178478944, 3: 0.11338767666675792, 6: 0.03984752280888322, 2: 0.11103556198250354}\n",
      "\n",
      "dist_1\n",
      "{1: 0.5880288679564248, 6: 0.0010725993678910644, 3: 0.08213804413205232, 2: 0.31054221229194046, 5: 0.0013733876414008962, 4: 0.016844888610290366}\n",
      "\n",
      "dist_0\n",
      "{1: 0.013882254955421636, 6: 0.30497777502726103, 3: 0.1797894931470431, 2: 0.11288961119763492, 5: 0.18268699440023994, 4: 0.20577387127239946}\n",
      "\n",
      "speed_1\n",
      "{3: 0.07914327314678785, 6: 0.0011024575482090444, 4: 0.00749925382155522, 2: 0.5217497208692008, 5: 0.0015470335717398427, 1: 0.3889582610425074}\n",
      "\n",
      "speed_0\n",
      "{3: 0.3003345437419287, 6: 0.14539320933382274, 4: 0.2868643474444838, 2: 0.07860170148041025, 5: 0.18302508507298657, 1: 0.00578111292636787}\n",
      "\n",
      "pass_1\n",
      "{3: 0.0876666056478112, 2: 0.19306991226723752, 1: 0.6447089929120811, 4: 0.07455448917287026}\n",
      "\n",
      "pass_0\n",
      "{3: 0.05956224182185543, 2: 0.12725815814793023, 1: 0.7117216694054224, 4: 0.1014579306247919}\n",
      "\n",
      "Out of sample prediction accuracy: 0.6804201050262566\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier=EM(X_train_Labeled,y_train_Labeled,X_train_Unlabeled,num_iters=50)\n",
    "for i,j in naive_bayes_classifier.items():\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print()\n",
    "y_pred_test = testNaiveBayesDiscrete(X_test,naive_bayes_classifier)\n",
    "\n",
    "# measure accuracy for the binary prediction task\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised EM clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4. Taxi trip clustering with no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Unlabeled=X_train # assume all observations are unlabeled\n",
    "X_train_Labeled=X_train.iloc[[],:] # empty\n",
    "y_train_Labeled=y_train.iloc[[]] # empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 50\n",
      "Iteration 2 of 50\n",
      "Iteration 3 of 50\n",
      "Iteration 4 of 50\n",
      "Iteration 5 of 50\n",
      "Iteration 6 of 50\n",
      "Iteration 7 of 50\n",
      "Iteration 8 of 50\n",
      "Iteration 9 of 50\n",
      "Iteration 10 of 50\n",
      "Iteration 11 of 50\n",
      "Iteration 12 of 50\n",
      "Iteration 13 of 50\n",
      "Iteration 14 of 50\n",
      "Iteration 15 of 50\n",
      "Iteration 16 of 50\n",
      "Iteration 17 of 50\n",
      "Iteration 18 of 50\n",
      "Iteration 19 of 50\n",
      "Iteration 20 of 50\n",
      "Iteration 21 of 50\n",
      "Iteration 22 of 50\n",
      "Iteration 23 of 50\n",
      "Iteration 24 of 50\n",
      "Iteration 25 of 50\n",
      "Iteration 26 of 50\n",
      "Iteration 27 of 50\n",
      "Iteration 28 of 50\n",
      "Iteration 29 of 50\n",
      "Iteration 30 of 50\n",
      "Iteration 31 of 50\n",
      "Iteration 32 of 50\n",
      "Iteration 33 of 50\n",
      "Iteration 34 of 50\n",
      "Iteration 35 of 50\n",
      "Iteration 36 of 50\n",
      "Iteration 37 of 50\n",
      "Iteration 38 of 50\n",
      "Iteration 39 of 50\n",
      "Iteration 40 of 50\n",
      "Iteration 41 of 50\n",
      "Iteration 42 of 50\n",
      "Iteration 43 of 50\n",
      "Iteration 44 of 50\n",
      "Iteration 45 of 50\n",
      "Iteration 46 of 50\n",
      "Iteration 47 of 50\n",
      "Iteration 48 of 50\n",
      "Iteration 49 of 50\n",
      "Iteration 50 of 50\n",
      "prior\n",
      "0.5482044061546144\n",
      "\n",
      "tip_1\n",
      "{1: 0.4263107278822063, 5: 0.05409273192419489, 4: 0.1662998296517521, 2: 0.15006890232540573, 3: 0.14797536497741656, 6: 0.05525244323902453}\n",
      "\n",
      "tip_0\n",
      "{1: 0.5146371500023522, 5: 0.054007122700316317, 4: 0.16655788166963906, 2: 0.11147563154034384, 3: 0.1140159095205883, 6: 0.03930630456676029}\n",
      "\n",
      "dist_1\n",
      "{2: 0.31214616300644754, 1: 0.5805121020752859, 6: 0.0019580503454481864, 3: 0.08403859971581909, 4: 0.019377007890456193, 5: 0.0019680769665432227}\n",
      "\n",
      "dist_0\n",
      "{2: 0.10480085947956626, 1: 0.00516002904539023, 6: 0.31334796696632505, 3: 0.18051813272942757, 4: 0.20857284806425672, 5: 0.187600163715034}\n",
      "\n",
      "speed_1\n",
      "{4: 0.008542554206552689, 1: 0.3827923618708317, 2: 0.5212065651811925, 3: 0.08427987417923119, 5: 0.001470558074059837, 6: 0.0017080864881320451}\n",
      "\n",
      "speed_0\n",
      "{4: 0.2942803639366407, 1: 0.0013545971870367296, 2: 0.06548886303747152, 3: 0.3009758963109911, 5: 0.18875774981454316, 6: 0.14914252971331685}\n",
      "\n",
      "pass_1\n",
      "{1: 0.6456402971434181, 4: 0.07511535138683824, 2: 0.19223543748359792, 3: 0.08700891398614569}\n",
      "\n",
      "pass_0\n",
      "{1: 0.7126742151255223, 4: 0.1016134754574014, 2: 0.12622544208423736, 3: 0.059486867332838894}\n",
      "\n",
      "Out of sample prediction accuracy: 0.68192048012003\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier=EM(X_train_Labeled,y_train_Labeled,X_train_Unlabeled,num_iters=50)\n",
    "for i,j in naive_bayes_classifier.items():\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print()\n",
    "y_pred_test = testNaiveBayesDiscrete(X_test,naive_bayes_classifier)\n",
    "\n",
    "# check if labels switched\n",
    "if (1.0*sum((y_pred_test>0.5)==y_test)/len(y_test) < 0.5):\n",
    "    y_pred_test = 1.0-y_pred_test\n",
    "print('Out of sample prediction accuracy:',1.0*sum((y_pred_test>0.5)==y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
